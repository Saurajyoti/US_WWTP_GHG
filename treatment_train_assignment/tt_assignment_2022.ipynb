{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "IiInbKv2DVeA",
   "metadata": {
    "id": "IiInbKv2DVeA"
   },
   "source": [
    "Date: 05/07/2025\n",
    "\n",
    "Point of Contact: Abigayle Hodson, Abigayle_Hodson@lbl.gov\n",
    "\n",
    "Organization: Lawrence Berkeley National Laboratory\n",
    "\n",
    "Purpose: The purpose of this notebook is to use data from a variety of sources, primarily various releases of the Clean Watersheds Needs Survey (CWNS), to create a dataframe of active wastewater treatment plants in the United States as of 2022. In addition to including flow rate, this dataframe also contains one or more treatment train assignments for each wastewater treatment plant based on *A Guide to Net-Zero Energy Solutions for Water Resource Recovery Facilities* (Tarallo et al., 2015). Treatment train assignments are ultimately used to estimate baseline energy consumption/generation and greenhouse gas emissions on a national scale from wastewater treament facilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9e955d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1914,
     "status": "ok",
     "timestamp": 1746638419348,
     "user": {
      "displayName": "Abigayle Hodson",
      "userId": "02880304820331263887"
     },
     "user_tz": 420
    },
    "id": "1f9e955d",
    "outputId": "a2fc1423-5d27-4678-8b58-a716ffb84efe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive/\n"
     ]
    }
   ],
   "source": [
    "#mount google drive - establishes a connection between Google Drive and Colab notebook\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/', force_remount=True)\n",
    "\n",
    "#import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BaK4pDQ1aQ8t",
   "metadata": {
    "id": "BaK4pDQ1aQ8t"
   },
   "source": [
    "# Create main dataframe of wastewater treatment plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "O-CE_Ii1t_8C",
   "metadata": {
    "id": "O-CE_Ii1t_8C"
   },
   "outputs": [],
   "source": [
    "def create_wwtp_inventory():\n",
    "  '''\n",
    "  Function that creates an inventory of active wwtps in the United States for 2022 using CWNS data\n",
    "    Returns:\n",
    "      wwtps_all = dataframe containing the active wwtps and relevant characteristics (ie. location, flow rate, and nutrient removal flags) for 2022\n",
    "  '''\n",
    "  #upload facility flow rates from 2022 CWNS\n",
    "  flow = pd.read_csv('/input_data/FLOW_2022.csv', dtype = {'CWNS_ID':str})\n",
    "\n",
    "  #filter to total flow\n",
    "  flow = flow.loc[flow['FLOW_TYPE'] == 'Total Flow']\n",
    "\n",
    "  #filter to facilities that report non-zero, non-nan flow in 2022\n",
    "  flow = flow.loc[(flow['CURRENT_DESIGN_FLOW'] != 0) & (~pd.isna(flow['CURRENT_DESIGN_FLOW']))]\n",
    "  flow.reset_index(inplace = True, drop = True)\n",
    "\n",
    "  #create dataframe of active wwtps based on facilities that report flow in 2022\n",
    "  wwtps_all = flow[['CWNS_ID', 'CURRENT_DESIGN_FLOW', 'FUTURE_DESIGN_FLOW']].rename(columns = {'CURRENT_DESIGN_FLOW':'FLOW_2022_MGD', 'FUTURE_DESIGN_FLOW':'FLOW_PROJ_MGD'})\n",
    "\n",
    "  #upload columns indicating nutrient removal in 2012 (note, 2022 CWNS does not include these columns, so we have to rely on outdated information)\n",
    "  nutr_rem = pd.read_excel('/input_data/2012_SUMMARY_EFFLUENT.xlsx', sheet_name = 'SUMMARY_EFFLUENT', dtype = {'CWNS_NUMBER':str})\n",
    "  nutr_rem = nutr_rem[['CWNS_NUMBER','PRES_NITROGEN_REMOVAL','PRES_PHOSPHOROUS_REMOVAL','PRES_AMMONIA_REMOVAL']].rename(columns = {'CWNS_NUMBER':'CWNS_ID'})\n",
    "\n",
    "  #merge nutrient removal information with main dataframe and rename columns\n",
    "  wwtps_all = wwtps_all.merge(nutr_rem, on = 'CWNS_ID', how = 'left')\n",
    "\n",
    "  #upload facility locations\n",
    "  locations = pd.read_csv('/input_data/2022_FACILITIES.csv', dtype = {'CWNS_ID':str})\n",
    "\n",
    "  #add state column to main dataframe\n",
    "  wwtps_all = wwtps_all.merge(locations[['CWNS_ID','STATE_CODE']], on = 'CWNS_ID', how = 'left')\n",
    "  wwtps_all.rename(columns = {'CWNS_ID':'CWNS_NUM','STATE_CODE':'STATE'}, inplace = True)\n",
    "\n",
    "  #upload facility types\n",
    "  types = pd.read_csv('/input_data/2022_FACILITY_TYPES.csv', dtype = {'CWNS_ID':str}).rename(columns= {'CWNS_ID':'CWNS_NUM'})\n",
    "\n",
    "  #filter to just treatment plants and honey bucket lagoons\n",
    "  types = types.loc[(types['FACILITY_TYPE'] == 'Treatment Plant') | (types['FACILITY_TYPE'] == 'Honey Bucket Lagoon')].drop_duplicates(subset = 'CWNS_NUM')\n",
    "  types.reset_index(inplace = True, drop = True)\n",
    "\n",
    "  #merge facility types with main dataframe to screen out non-treatment plants and honey bucket lagoons from inventory\n",
    "  wwtps_all = wwtps_all.merge(types[['CWNS_NUM','FACILITY_TYPE']], on = 'CWNS_NUM', how = 'inner')\n",
    "\n",
    "  #categorize average daily flow rate\n",
    "  wwtps_all.loc[wwtps_all['FLOW_2022_MGD'] < 2, '2022_FLOW_CAT_MGD'] = 'LESS THAN 2'\n",
    "  wwtps_all.loc[(wwtps_all['FLOW_2022_MGD'] >= 2) & (wwtps_all['FLOW_2022_MGD'] < 4), '2022_FLOW_CAT_MGD'] = '2 TO 4'\n",
    "  wwtps_all.loc[(wwtps_all['FLOW_2022_MGD'] >= 4) & (wwtps_all['FLOW_2022_MGD'] < 7), '2022_FLOW_CAT_MGD'] = '4 TO 7'\n",
    "  wwtps_all.loc[(wwtps_all['FLOW_2022_MGD'] >= 7) & (wwtps_all['FLOW_2022_MGD'] < 16), '2022_FLOW_CAT_MGD'] = '7 TO 16'\n",
    "  wwtps_all.loc[(wwtps_all['FLOW_2022_MGD'] >= 16) & (wwtps_all['FLOW_2022_MGD'] < 46), '2022_FLOW_CAT_MGD'] = '16 TO 46'\n",
    "  wwtps_all.loc[(wwtps_all['FLOW_2022_MGD'] >= 46) & (wwtps_all['FLOW_2022_MGD'] < 100), '2022_FLOW_CAT_MGD'] = '46 TO 100'\n",
    "  wwtps_all.loc[(wwtps_all['FLOW_2022_MGD'] >= 100), '2022_FLOW_CAT_MGD'] = '100 AND ABOVE'\n",
    "\n",
    "  #categorize projected flow rate\n",
    "  wwtps_all.loc[wwtps_all['FLOW_PROJ_MGD'] < 2, 'PROJ_FLOW_CAT_MGD'] = 'LESS THAN 2'\n",
    "  wwtps_all.loc[(wwtps_all['FLOW_PROJ_MGD'] >= 2) & (wwtps_all['FLOW_PROJ_MGD'] < 4), 'PROJ_FLOW_CAT_MGD'] = '2 TO 4'\n",
    "  wwtps_all.loc[(wwtps_all['FLOW_PROJ_MGD'] >= 4) & (wwtps_all['FLOW_PROJ_MGD'] < 7), 'PROJ_FLOW_CAT_MGD'] = '4 TO 7'\n",
    "  wwtps_all.loc[(wwtps_all['FLOW_PROJ_MGD'] >= 7) & (wwtps_all['FLOW_PROJ_MGD'] < 16), 'PROJ_FLOW_CAT_MGD'] = '7 TO 16'\n",
    "  wwtps_all.loc[(wwtps_all['FLOW_PROJ_MGD'] >= 16) & (wwtps_all['FLOW_PROJ_MGD'] < 46), 'PROJ_FLOW_CAT_MGD'] = '16 TO 46'\n",
    "  wwtps_all.loc[(wwtps_all['FLOW_PROJ_MGD'] >= 46) & (wwtps_all['FLOW_PROJ_MGD'] < 100), 'PROJ_FLOW_CAT_MGD'] = '46 TO 100'\n",
    "  wwtps_all.loc[(wwtps_all['FLOW_PROJ_MGD'] >= 100), 'PROJ_FLOW_CAT_MGD'] = '100 AND ABOVE'\n",
    "\n",
    "  #upload EPA regions by state\n",
    "  epa_regions = pd.read_csv('/input_data/state_EPA_regions.csv', dtype = {'STATE':str})\n",
    "\n",
    "  #add column for EPA region\n",
    "  wwtps_all = wwtps_all.merge(epa_regions, on = 'STATE', how = 'left')\n",
    "\n",
    "  #check for facilities with duplicate entries\n",
    "  assert wwtps_all['CWNS_NUM'].value_counts().max() == 1\n",
    "\n",
    "  return wwtps_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687bd964",
   "metadata": {
    "collapsed": true,
    "id": "687bd964",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#create inventory of active wwtps in 2022\n",
    "wwtps = create_wwtp_inventory()\n",
    "\n",
    "#add leading zero to CWNS ids with less than 11 digits to ensure correct merge with other datasets\n",
    "wwtps['CWNS_NUM'] = ['0' + str(cwns) if len(str(cwns)) < 11 else str(cwns) for cwns in wwtps['CWNS_NUM']]\n",
    "\n",
    "#filter to wwtps in the contiguous United States and reset indexing\n",
    "wwtps = wwtps.loc[(wwtps['STATE'] != 'PR') & (wwtps['STATE'] != 'AK') & (wwtps['STATE'] != 'VI') & (wwtps['STATE'] != 'HI') & (wwtps['STATE'] != 'MP') & (wwtps['STATE'] != 'GU') & (wwtps['STATE'] != 'AS')]\n",
    "wwtps.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ffddf9",
   "metadata": {
    "collapsed": true,
    "id": "69ffddf9"
   },
   "outputs": [],
   "source": [
    "#read in data from the Water Environment Federation's (WEF) biogas database (https://app.powerbi.com/view?r=eyJrIjoiMGFjZDFjZmItMjQ5Yi00ZTlhLWJmNTQtODFiNjlkYjFlODJjIiwidCI6ImI3ZTk3ODAyLTJhNjktNDc3ZS1iN2QyLWY0ZDE2MWMyMTBjYiIsImMiOjF9) to identify wwtps that utilize biogas for electricity generation; note, data was pulled ~2018 before website switched to MS BI\n",
    "wef_biogas = pd.read_csv(/input_data/WERF_BIOGAS.csv', dtype = {'CWNS_NUM' : str}, encoding = 'latin1')\n",
    "\n",
    "#change formatting of WEF data from string to binary\n",
    "wef_biogas.loc[wef_biogas['Electricity_from_combustion-engine'] != 'yes', 'Electricity_from_combustion-engine'] = 0\n",
    "wef_biogas.loc[wef_biogas['Electricity_from_combustion-engine'] == 'yes', 'Electricity_from_combustion-engine'] = 1\n",
    "wef_biogas.loc[wef_biogas['Electricity_from_microturbine'] != 'yes', 'Electricity_from_microturbine'] = 0\n",
    "wef_biogas.loc[wef_biogas['Electricity_from_microturbine'] == 'yes', 'Electricity_from_microturbine'] = 1\n",
    "wef_biogas.loc[wef_biogas['Electricity_from_turbine'] != 'yes', 'Electricity_from_turbine'] = 0\n",
    "wef_biogas.loc[wef_biogas['Electricity_from_turbine'] == 'yes', 'Electricity_from_turbine'] = 1\n",
    "wef_biogas.loc[wef_biogas['Electricity_from_fuelcell'] != 'yes', 'Electricity_from_fuelcell'] = 0\n",
    "wef_biogas.loc[wef_biogas['Electricity_from_fuelcell'] == 'yes', 'Electricity_from_fuelcell'] = 1\n",
    "wef_biogas.loc[wef_biogas['Electricity_supplied_to_grid'] != 'yes', 'Electricity_supplied_to_grid'] = 0\n",
    "wef_biogas.loc[wef_biogas['Electricity_supplied_to_grid'] == 'yes', 'Electricity_supplied_to_grid'] = 1\n",
    "wef_biogas.loc[wef_biogas['AD'] == 'yes', 'AD'] = 1\n",
    "\n",
    "#create column that indicates if biogas is used to generate electricity\n",
    "wef_biogas['biogas_werf'] = wef_biogas['Electricity_from_combustion-engine'] + wef_biogas['Electricity_from_microturbine'] + wef_biogas['Electricity_from_turbine'] + wef_biogas['Electricity_from_fuelcell'] + wef_biogas['Electricity_supplied_to_grid']\n",
    "wef_biogas.loc[wef_biogas['biogas_werf'] > 0, 'BIOGASELEC_WERF'] = 1\n",
    "\n",
    "#drop nan values from biogas dataframe to avoid creating duplicates in wwtps dataframe post-merge\n",
    "wef_biogas = wef_biogas.dropna(subset = 'CWNS_NUM')\n",
    "\n",
    "#add a leading zero to CWNS ids with a length less than 11 to ensure proper merge\n",
    "wef_biogas['CWNS_NUM'] = ['0' + str(cwns) if len(str(cwns)) < 11 else str(cwns) for cwns in wef_biogas['CWNS_NUM']]\n",
    "\n",
    "#create new dataframe that just indicates whether biogas is utilized for electricity generation, according to WEF\n",
    "biogas_wef = wef_biogas[['CWNS_NUM','BIOGASELEC_WERF']].dropna()\n",
    "\n",
    "#merge biogas info from WEF with faciltiies info from CWNS\n",
    "wwtps = pd.merge(left = wwtps, right = biogas_wef, how = 'left', on = 'CWNS_NUM')\n",
    "\n",
    "#replace nan values with zeros\n",
    "wwtps['BIOGASELEC_WERF'] = wwtps['BIOGASELEC_WERF'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7687ee",
   "metadata": {
    "id": "ff7687ee"
   },
   "outputs": [],
   "source": [
    "#read in data from the Department of Energy's Combined Heat and Power Installation database (https://doe.icfwebservices.com/chp) to identify wwtps that utilize biogas for electricity generation\n",
    "doe_biogas = pd.read_csv(/input_data/doe_chpdb-WWTP.csv', dtype = {'CWNS_NUM' : str}, encoding = 'latin1')\n",
    "\n",
    "#drop duplicate and nan values from biogas dataframe to avoid creating duplicates in wwtps dataframe post-merge\n",
    "doe_biogas.dropna(subset = 'CWNS_NUM', inplace = True)\n",
    "\n",
    "#add a leading zero to old CWNS ids with a length less than 11 to ensure proper merge\n",
    "doe_biogas['CWNS_NUM'] = ['0' + str(cwns) if len(str(cwns)) < 11 else str(cwns) for cwns in doe_biogas['CWNS_NUM']]\n",
    "doe_biogas.drop_duplicates(subset = 'CWNS_NUM', inplace = True)\n",
    "\n",
    "#create a dataframe that just indicates whether biogas is used for electricity generation, according to DOE\n",
    "biogas_doe = doe_biogas[['CWNS_NUM','BIOGAS_DOE_2022']]\n",
    "\n",
    "#merge biogas info from DOE with faciltiies info from CWNS\n",
    "wwtps = pd.merge(left = wwtps, right = biogas_doe, how = 'left', on = 'CWNS_NUM')\n",
    "\n",
    "#replace nan values with zeros\n",
    "wwtps['BIOGAS_DOE_2022'] = wwtps['BIOGAS_DOE_2022'].fillna(0)\n",
    "\n",
    "#create column that indicate whether biogas was used for electricity generation based on the results of both DOE and WEF\n",
    "wwtps['BIOGAS_EL_2022'] = 0\n",
    "wwtps.loc[((wwtps['BIOGASELEC_WERF'] + wwtps['BIOGAS_DOE_2022']) > 0), 'BIOGAS_EL_2022'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Sb6KPHlpablK",
   "metadata": {
    "id": "Sb6KPHlpablK"
   },
   "source": [
    "# Create cumulative unit process list for wastewater treatment plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f12d70d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 958,
     "status": "ok",
     "timestamp": 1746639674709,
     "user": {
      "displayName": "Abigayle Hodson",
      "userId": "02880304820331263887"
     },
     "user_tz": 420
    },
    "id": "2f12d70d",
    "outputId": "03b4dd95-c884-402d-fcfc-63b425562a24"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-101-0bf849682014>:27: DtypeWarning: Columns (14,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  up2004 = pd.read_csv('/content/gdrive/MyDrive/AMO/baselining_paper/treatment_train_assignment/input_data/2004_Unit_Processes.csv', dtype = {'REPORT_YEAR':int, \"CWNS_NUMBER\":str, \"TREATMENT_TYPE\":str,\"UNIT_PROCESS\":str}, encoding = 'latin1')\n"
     ]
    }
   ],
   "source": [
    "#read in unit processes from the 2022 CWNS\n",
    "up2022 = pd.read_csv(/input_data/2022_SUMMARY_UNIT_PROCESSES.csv', dtype = {\"CWNS_ID\" : str})\n",
    "up2022.rename(columns = {'CWNS_ID':'CWNS_NUM'}, inplace = True)\n",
    "\n",
    "#add a leading zero to CWNS ids with a length less than 11 to ensure proper merge\n",
    "up2022['CWNS_NUM'] = ['0' + str(cwns) if len(str(cwns)) < 11 else str(cwns) for cwns in up2022['CWNS_NUM']]\n",
    "\n",
    "#change formatting of 2022 unit process names to match that of prior years\n",
    "#note: 'Biological Treatment, Other' was manually corrected to be more specific. 'Chemical N Removal' was assumed to be roughly the same energy intensity as 'Chemical P removal'\n",
    "upnames_2022 = pd.read_csv(/input_data/UNIT_PROCESS_NAMES_2022.csv')\n",
    "up2022 = pd.merge(left = up2022, right = upnames_2022, how = 'left', left_on = 'UNIT_PROCESS', right_on = '2022_UNIT_PROCESS_NAME')\n",
    "\n",
    "#filter to relevant columns and rename to match the formatting of old unit process dataframes\n",
    "up2022 = up2022[['CWNS_NUM','FINAL_UNIT_PROCESS_NAME','EXISTING_FLAG','PLANNED_FLAG']]\n",
    "up2022.rename(columns = {'EXISTING_FLAG':'PRES_IND','PLANNED_FLAG':'PROJ_IND'}, inplace = True)\n",
    "up2022.loc[up2022['PRES_IND'] == 'Y', 'PRES_IND'] = 1\n",
    "up2022.loc[up2022['PRES_IND'] == 'N', 'PRES_IND'] = 0\n",
    "up2022.loc[pd.isna(up2022['PRES_IND']), 'PRES_IND'] = 0\n",
    "up2022.loc[up2022['PROJ_IND'] == 'Y', 'PROJ_IND'] = 1\n",
    "up2022.loc[up2022['PROJ_IND'] == 'N', 'PROJ_IND'] = 0\n",
    "up2022.loc[pd.isna(up2022['PROJ_IND']), 'PROJ_IND'] = 0\n",
    "up2022['REPORT_YEAR'] = 2022\n",
    "\n",
    "#read in unit processs reported in the 2004, 2008, and 2012 releases of CWNS\n",
    "up2012 = pd.read_csv(/input_data/2012_SUMMARY_UNIT_PROCESS.csv', dtype = {'REPORT_YEAR':int, \"CWNS_NUMBER\":str, \"TREATMENT_TYPE\":str,\"UNIT_PROCESS\":str}, encoding = 'latin1')\n",
    "up2008 = pd.read_csv(/input_data/2008_SUMMARY_UNIT_PROCESS.csv',dtype = {'REPORT_YEAR':int, \"CWNS_NUMBER\":str, \"TREATMENT_TYPE\":str,\"UNIT_PROCESS\":str}, encoding = 'latin1')\n",
    "up2004 = pd.read_csv(/input_data/2004_Unit_Processes.csv', dtype = {'REPORT_YEAR':int, \"CWNS_NUMBER\":str, \"TREATMENT_TYPE\":str,\"UNIT_PROCESS\":str}, encoding = 'latin1')\n",
    "\n",
    "#aggregate 2004, 2008, and 2012 unit process lists\n",
    "up_old = pd.concat([up2012, up2008,up2004], axis = 0)\n",
    "up_old.drop(['BACKUP_IND','PLANNED_YEAR','ADDITIONAL_NOTES','LAST_UPDATED_TS','BLANK','CHANGE_TYPE_CAT','SORT_SEQUENCE','KEEP_UP_CODE', 'CHGTP_NAME_CAT','TREATMENT_TYPE','Notes'], inplace = True, axis = 1)\n",
    "up_old.rename(columns = {'CWNS_NUMBER':'CWNS_NUM'}, inplace = True)\n",
    "\n",
    "#add a leading zero to CWNS ids with a length less than 11 to ensure proper merge\n",
    "up_old['CWNS_NUM'] = ['0' + str(cwns) if len(str(cwns)) < 11 else str(cwns) for cwns in up_old['CWNS_NUM']]\n",
    "\n",
    "#reconcile unit process naming conventions between report years\n",
    "upnames = pd.read_csv(/input_data/UNIT_PROCESS_NAMES.csv')\n",
    "up_old = pd.merge(left = up_old, right = upnames, how = 'left', left_on = 'UNIT_PROCESS', right_on = 'ORIGINAL_UP_NAME')\n",
    "up_old.drop(['ORIGINAL_UP_NAME'], inplace = True, axis = 1)\n",
    "\n",
    "#remove processes listed for abandoment in 2004, 2008, or 2012 and processes listed as both PRES_IND = N and PROJ_IND = N\n",
    "up_old = up_old.loc[up_old['CHANGE_TYPE'] != 'Abandonment']\n",
    "up_old = up_old.loc[~((up_old['PRES_IND'] == 'N') & (up_old['PRES_IND'] == 'N'))]\n",
    "up_old = up_old[['CWNS_NUM','REPORT_YEAR','PRES_IND','PROJ_IND','FINAL_UNIT_PROCESS_NAME']]\n",
    "\n",
    "#change formatting of present and projected indices to binary\n",
    "up_old.loc[up_old['PRES_IND'] == 'Y', 'PRES_IND'] = 1\n",
    "up_old.loc[up_old['PRES_IND'] == 'N', 'PRES_IND'] = 0\n",
    "up_old.loc[up_old['PROJ_IND'] == 'Y', 'PROJ_IND'] = 1\n",
    "up_old.loc[up_old['PROJ_IND'] == 'N', 'PROJ_IND'] = 0\n",
    "\n",
    "#join 2022 unit process list and old unit process list\n",
    "uplist_all = pd.concat([up2022, up_old], axis = 0)\n",
    "\n",
    "#sort by CWNS ID and reporting year\n",
    "uplist_all.sort_values(by = ['CWNS_NUM','REPORT_YEAR'], ascending = True, inplace = True)\n",
    "\n",
    "#drop duplicate unit processes and keep most recent entry\n",
    "uplist_all.drop_duplicates(subset = ['CWNS_NUM', 'FINAL_UNIT_PROCESS_NAME','PRES_IND','PROJ_IND'], inplace = True, keep = 'last')\n",
    "uplist_recent = uplist_all.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d057429",
   "metadata": {
    "id": "4d057429"
   },
   "outputs": [],
   "source": [
    "#use supplementary biogas databases to add anaerobic digestion to unit process list for facilities flagged as using biogas for electricity production\n",
    "wef_biogas_ad = wef_biogas[['CWNS_NUM', 'AD']].drop_duplicates(subset = 'CWNS_NUM')\n",
    "wef_biogas_ad.loc[wef_biogas_ad['AD'] == 1, 'FINAL_UNIT_PROCESS_NAME'] = 'Biosolids Anaerobic Digestion, Other'\n",
    "wef_biogas_ad['REPORT_YEAR'] = 2013\n",
    "wef_biogas_ad['PRES_IND'] = 1\n",
    "wef_biogas_ad['PROJ_IND'] = 1\n",
    "wef_biogas_ad = wef_biogas_ad[['CWNS_NUM','FINAL_UNIT_PROCESS_NAME','REPORT_YEAR','PRES_IND','PROJ_IND']]\n",
    "\n",
    "doe_biogas_ad = doe_biogas.loc[doe_biogas['BIOGAS_DOE_2022'] == 1][['CWNS_NUM','Last Verified']]\n",
    "doe_biogas_ad.rename(columns = {'Last Verified':'REPORT_YEAR'}, inplace = True)\n",
    "doe_biogas_ad['FINAL_UNIT_PROCESS_NAME'] = 'Biosolids Anaerobic Digestion, Other'\n",
    "doe_biogas_ad['PRES_IND'] = 1\n",
    "doe_biogas_ad['PROJ_IND'] = 1\n",
    "\n",
    "#merge additional anaerobic digestion processes with cumulative unit process list\n",
    "uplist_recent = pd.concat([uplist_recent, wef_biogas_ad, doe_biogas_ad], axis = 0, ignore_index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558ee22c",
   "metadata": {
    "id": "558ee22c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#assign key unit processes a code (ie. 'Activated Sludge' is assigned the code 'AS'); note, not all unit processes receive a code\n",
    "up_eicodes = pd.read_csv(/input_data/UNIT_PROCESS_EI_CODES_WERF.csv')\n",
    "uplist_eicodes = uplist_recent.merge(up_eicodes[['FINAL_UNIT_PROCESS_NAME','WERF_CODE','DISPOSAL_CODE']].drop_duplicates(subset = ['FINAL_UNIT_PROCESS_NAME']), how = 'left', on = 'FINAL_UNIT_PROCESS_NAME')\n",
    "\n",
    "#create column to indicate if a unit process was present in 2022\n",
    "uplist_eicodes['2022_MIN_IND'] = uplist_eicodes['PRES_IND']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f32bfaa",
   "metadata": {
    "collapsed": true,
    "id": "4f32bfaa"
   },
   "outputs": [],
   "source": [
    "#manual corrections to cumulative unit process list (Christina Polcuch, 2023) for large facilities that were initially assigned multiple treatment trains\n",
    "#here, we conducted manual verification of unit processes for selected facilities using publicly available information. Relevant unit processes were updated accordingly in the unit process list, and the note \"Corrected based on manual check of large facilities with multiple treatment train assignments (2023)\" was added in the UP_ID_NOTE column.\n",
    "\n",
    "#fix Lewiston, ME; no nutrient removal\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '23000011001') & ((uplist_eicodes['WERF_CODE'] == 'AS-A2O')), '2022_MIN_IND'] = 0\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '23000011001') & ((uplist_eicodes['WERF_CODE'] == 'AS-A2O')), 'PRES_IND'] = 0\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '23000011001') & ((uplist_eicodes['WERF_CODE'] == 'AS-A2O')), 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'\n",
    "\n",
    "#fix Brockton, MA; no TF, no incineration\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '25000024001') & ((uplist_eicodes['WERF_CODE'] == 'TF')), '2022_MIN_IND'] = 0\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '25000024001') & ((uplist_eicodes['WERF_CODE'] == 'TF')), 'PROJ_IND'] = 0\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '25000024001') & ((uplist_eicodes['WERF_CODE'] == 'TF')), 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '25000024001') & ((uplist_eicodes['WERF_CODE'] == 'MHI')), '2022_MIN_IND'] = 0\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '25000024001') & ((uplist_eicodes['WERF_CODE'] == 'MHI')), 'PROJ_IND'] = 0\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '25000024001') & ((uplist_eicodes['WERF_CODE'] == 'MHI')), 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'\n",
    "\n",
    "#fix GLWA plants; no phosphorus or nutrient removal\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '26000569001') & ((uplist_eicodes['WERF_CODE'] == 'AS-A2O')), '2022_MIN_IND'] = 0\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '26000569001') & ((uplist_eicodes['WERF_CODE'] == 'AS-A2O')), 'PRES_IND'] = 0\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '26000569001') & ((uplist_eicodes['WERF_CODE'] == 'AS-A2O')), 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'\n",
    "\n",
    "#fix WY WWTP; no trickling filter\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '26000334001') & ((uplist_eicodes['WERF_CODE'] == 'TF')), '2022_MIN_IND'] = 0\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '26000334001') & ((uplist_eicodes['WERF_CODE'] == 'TF')), 'PRES_IND'] = 0\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '26000334001') & ((uplist_eicodes['WERF_CODE'] == 'TF')), 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'\n",
    "\n",
    "#fix Mcalpine Creek WWTP; no BNIT, LAGOON_AER, NIT, or TF; add biogas utilization\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '37006001002') & ((uplist_eicodes['WERF_CODE'] == 'BNIT')), '2022_MIN_IND'] = 0\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '37006001002') & ((uplist_eicodes['WERF_CODE'] == 'BNIT')), 'PRES_IND'] = 0\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '37006001002') & ((uplist_eicodes['WERF_CODE'] == 'BNIT')), 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '37006001002') & ((uplist_eicodes['WERF_CODE'] == 'LAGOON_AER')), '2022_MIN_IND'] = 0\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '37006001002') & ((uplist_eicodes['WERF_CODE'] == 'LAGOON_AER')), 'PRES_IND'] = 0\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '37006001002') & ((uplist_eicodes['WERF_CODE'] == 'LAGOON_AER')), 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '37006001002') & ((uplist_eicodes['WERF_CODE'] == 'NIT')), '2022_MIN_IND'] = 0\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '37006001002') & ((uplist_eicodes['WERF_CODE'] == 'NIT')), 'PRES_IND'] = 0\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '37006001002') & ((uplist_eicodes['WERF_CODE'] == 'NIT')), 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '37006001002') & ((uplist_eicodes['WERF_CODE'] == 'TF')), '2022_MIN_IND'] = 0\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '37006001002') & ((uplist_eicodes['WERF_CODE'] == 'TF')), 'PRES_IND'] = 0\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '37006001002') & ((uplist_eicodes['WERF_CODE'] == 'TF')), 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'\n",
    "wwtps.loc[wwtps['CWNS_NUM'] == '37006001002', 'BIOGAS_EL_2022'] = 1\n",
    "\n",
    "#fix NEORSD Westerly WWTP; no AND, AS, or CHEM-P\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '39001666003') & ((uplist_eicodes['WERF_CODE'] == 'AND')), '2022_MIN_IND'] = 0\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '39001666003') & ((uplist_eicodes['WERF_CODE'] == 'AND')), 'PRES_IND'] = 0\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '39001666003') & ((uplist_eicodes['WERF_CODE'] == 'AND')), 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '39001666003') & ((uplist_eicodes['WERF_CODE'] == 'AS')), '2022_MIN_IND'] = 0\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '39001666003') & ((uplist_eicodes['WERF_CODE'] == 'AS')), 'PRES_IND'] = 0\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '39001666003') & ((uplist_eicodes['WERF_CODE'] == 'AS')), 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '39001666003') & ((uplist_eicodes['WERF_CODE'] == 'CHEM-P')), '2022_MIN_IND'] = 0\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '39001666003') & ((uplist_eicodes['WERF_CODE'] == 'CHEM-P')), 'PRES_IND'] = 0\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '39001666003') & ((uplist_eicodes['WERF_CODE'] == 'CHEM-P')), 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'\n",
    "\n",
    "#fix Hopewell Regional WWTP; no FBI, add MHI\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '51000238001') & ((uplist_eicodes['WERF_CODE'] == 'FBI')), '2022_MIN_IND'] = 0\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '51000238001') & ((uplist_eicodes['WERF_CODE'] == 'FBI')), 'PRES_IND'] = 0\n",
    "uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '51000238001') & ((uplist_eicodes['WERF_CODE'] == 'FBI')), 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'\n",
    "hopewell_idx = uplist_eicodes[uplist_eicodes['CWNS_NUM'] == '51000238001'].index.max()\n",
    "hopewell_add = pd.Series({'CWNS_NUM': '51000238001', 'WERF_CODE': 'MHI', '2022_MIN_IND': 1, 'PRES_IND': 1, 'FINAL_UNIT_PROCESS_NAME': 'Biosolids Incineration, Multiple Hearth', 'UP_ID_NOTE': 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'}).to_frame().T\n",
    "uplist_eicodes = pd.concat([uplist_eicodes.iloc[:hopewell_idx], hopewell_add, uplist_eicodes.iloc[hopewell_idx:]], ignore_index=True)\n",
    "\n",
    "#fix Arlington, CO WPCP; add LIME\n",
    "arlington_idx = uplist_eicodes[uplist_eicodes['CWNS_NUM'] == '51000319001'].index.max()\n",
    "arlington_add = pd.Series({'CWNS_NUM': '51000319001', 'WERF_CODE': 'LIME', '2022_MIN_IND': 1, 'PRES_IND': 1, 'FINAL_UNIT_PROCESS_NAME': 'Biosolids Lime Stabilization', 'UP_ID_NOTE': 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'}).to_frame().T\n",
    "uplist_eicodes = pd.concat([uplist_eicodes.iloc[:arlington_idx], arlington_add, uplist_eicodes.iloc[arlington_idx:]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250f9e05",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 964,
     "status": "ok",
     "timestamp": 1746639676927,
     "user": {
      "displayName": "Abigayle Hodson",
      "userId": "02880304820331263887"
     },
     "user_tz": 420
    },
    "id": "250f9e05",
    "outputId": "a4a551ef-b92b-4395-d8dc-07f84d00f3c8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-105-5e8c8eda376f>:21: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  uplist_eicodes['PROJ_IND'] = uplist_eicodes['PROJ_IND'].fillna(1)\n"
     ]
    }
   ],
   "source": [
    "#manual updates to add and remove lagoons (Christina Polcuch, 2023)\n",
    "#here, we confirmed the presence of lagoons at facilities larger than 10 MGD using publicly available information\n",
    "\n",
    "#import list of lagoons to add from EPA lagoon inventory and manual checks\n",
    "lagoon_add = pd.read_csv(/input_data/cwns_lagoon_add_ttrains_info.csv', dtype = {'CWNS_NUM':str})\n",
    "\n",
    "#add leading zeros to CWNS ids to ensure proper merge with other datasets\n",
    "lagoon_add['CWNS_NUM'] = ['0' + str(cwns) if len(str(cwns)) < 11 else str(cwns) for cwns in lagoon_add['CWNS_NUM']]\n",
    "\n",
    "#add in columns for concatenation with main uplist_eicodes dataframe\n",
    "lagoon_add['REPORT_YEAR'] = 2022\n",
    "lagoon_add['UP_ID_NOTE'] = 'Assigned using updated data on the presence of lagoons from EPA (2022)'\n",
    "lagoon_add['2022_MIN_IND'] = 1\n",
    "lagoon_add['PRES_IND'] = 1\n",
    "lagoon_add.rename(columns = {'LAGOON_CODE':'WERF_CODE','LAGOON_NAME':'FINAL_UNIT_PROCESS_NAME'}, inplace = True)\n",
    "\n",
    "#concatenate dataframe which contains additional lagoons found in EPA survey/manual checks and main unit process list dataframe\n",
    "uplist_eicodes = pd.concat([uplist_eicodes, lagoon_add], axis = 0)\n",
    "\n",
    "#assume lagoons that were added are projected to remain\n",
    "uplist_eicodes['PROJ_IND'] = uplist_eicodes['PROJ_IND'].fillna(1)\n",
    "\n",
    "#drop duplicates unit processes to ensure most recent lagoons are kept in final unit process list\n",
    "uplist_eicodes.sort_values(by = ['CWNS_NUM','REPORT_YEAR'], ascending = True, inplace = True)\n",
    "uplist_eicodes.drop_duplicates(subset = ['CWNS_NUM','WERF_CODE','DISPOSAL_CODE','PRES_IND','PROJ_IND'], inplace = True, keep = 'last')\n",
    "uplist_eicodes.reset_index(inplace = True, drop = True)\n",
    "\n",
    "#import list of lagoons to remove based on manual checks\n",
    "lagoon_removed = pd.read_csv(/input_data/cwns_lagoon_remove.csv', dtype = {'CWNS_NUM': str})\n",
    "\n",
    "#add leading zeros to CWNS ids to ensure proper match with uplist_eicodes\n",
    "lagoon_removed['CWNS_NUM'] = ['0' + str(cwns) if len(str(cwns)) < 11 else str(cwns) for cwns in lagoon_removed['CWNS_NUM']]\n",
    "\n",
    "#loop through lagoons that need to be removed\n",
    "for index, row in lagoon_removed.iterrows():\n",
    "    #get the CWNS number and lagoon code to remove\n",
    "    lagoon_removed_CWNS = row['CWNS_NUM']\n",
    "    lagoon_removed_code = row['REMOVE']\n",
    "\n",
    "    #search for the row in uplist_eicodes where the CWNS number matches the CWNS number in lagoon_removed\n",
    "    CWNS_match_row = uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == lagoon_removed_CWNS) & (uplist_eicodes['WERF_CODE'].str.contains(lagoon_removed_code))]\n",
    "\n",
    "    #if a matching row is found, set '2022_MIN_IND', '2022_MAX_IND', and 'PROJ_IND' equal to 0 and update 'UP_ID_NOTE'\n",
    "    if not CWNS_match_row.empty:\n",
    "        uplist_eicodes.loc[CWNS_match_row.index, ['2022_MIN_IND','PROJ_IND']] = 0\n",
    "        uplist_eicodes.loc[CWNS_match_row.index, 'UP_ID_NOTE'] = 'Corrected based on manual check of large lagoons (2023/2024)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bca9612",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 194,
     "status": "ok",
     "timestamp": 1746639677081,
     "user": {
      "displayName": "Abigayle Hodson",
      "userId": "02880304820331263887"
     },
     "user_tz": 420
    },
    "id": "9bca9612",
    "outputId": "6cf783c6-2215-429c-c30b-e53d7b0bb37a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-106-6d4f32a4413e>:7: FutureWarning: The provided callable <function sum at 0x7f129510cf40> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  disposal_2022_pvt = pd.pivot_table(disposal_2022, index = 'CWNS_NUM', values = 'PRES_IND',  columns = 'DISPOSAL_CODE', aggfunc = np.sum, fill_value = 0)\n",
      "<ipython-input-106-6d4f32a4413e>:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  disposal_2022_pvt = pd.pivot_table(disposal_2022, index = 'CWNS_NUM', values = 'PRES_IND',  columns = 'DISPOSAL_CODE', aggfunc = np.sum, fill_value = 0)\n"
     ]
    }
   ],
   "source": [
    "#identify plants that have FBI, MHI, LAND_APP, or LANDFILL as a biosolids disposal method in 2022 and export for use in biosolids emissions calculations\n",
    "disposal_2022 = uplist_eicodes[['CWNS_NUM','REPORT_YEAR','PRES_IND','DISPOSAL_CODE']]\n",
    "disposal_2022 = disposal_2022.loc[(disposal_2022['PRES_IND'] == 1)]\n",
    "disposal_2022 = disposal_2022.dropna(subset = ['DISPOSAL_CODE'])\n",
    "disposal_2022.sort_values(by = ['CWNS_NUM','REPORT_YEAR'], ascending = False, inplace = True, ignore_index = True)\n",
    "disposal_2022.drop_duplicates(subset = 'CWNS_NUM', inplace = True, ignore_index = False, keep = \"first\")\n",
    "disposal_2022_pvt = pd.pivot_table(disposal_2022, index = 'CWNS_NUM', values = 'PRES_IND',  columns = 'DISPOSAL_CODE', aggfunc = np.sum, fill_value = 0)\n",
    "disposal_2022_pvt.to_csv(/output_data/disposal_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Zo_7suqTdjnh",
   "metadata": {
    "id": "Zo_7suqTdjnh"
   },
   "outputs": [],
   "source": [
    "#drop unit processes that do not have an associated WERF code, as these are not necessary to form treatment train assignments\n",
    "uplist_eicodes.dropna(subset = 'WERF_CODE', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Mlwp2HVCg--r",
   "metadata": {
    "id": "Mlwp2HVCg--r"
   },
   "outputs": [],
   "source": [
    "#manual check for nutrient removal (Christina Polcuch, 2023)\n",
    "#for facilities where the cumulative unit process list was revised based on publicly available information, correct the nutrient removal flags in the main wwtps dataframe to remain consistent with uplist_eicodes\n",
    "\n",
    "#fix Lewiston, ME; remove nutrient removal\n",
    "wwtps.loc[wwtps['CWNS_NUM'] == '23000011001', 'PRES_NITROGEN_REMOVAL'] = 0\n",
    "wwtps.loc[wwtps['CWNS_NUM'] == '23000011001', 'PRES_PHOSPHOROUS_REMOVAL'] = 0\n",
    "wwtps.loc[wwtps['CWNS_NUM'] == '23000011001', 'PRES_AMMONIA_REMOVAL'] = 0\n",
    "uplist_eicodes.loc[uplist_eicodes['CWNS_NUM'] == '23000011001', 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'\n",
    "\n",
    "#fix GLWA plants; no phosphorus or nutrient removal yet\n",
    "wwtps.loc[wwtps['CWNS_NUM'] == '26000569001', 'PRES_NITROGEN_REMOVAL'] = 0\n",
    "wwtps.loc[wwtps['CWNS_NUM'] == '26000569001', 'PRES_PHOSPHOROUS_REMOVAL'] = 0\n",
    "wwtps.loc[wwtps['CWNS_NUM'] == '26000569001', 'PRES_AMMONIA_REMOVAL'] = 0\n",
    "uplist_eicodes.loc[uplist_eicodes['CWNS_NUM'] == '26000569001', 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d6a8ac",
   "metadata": {
    "collapsed": true,
    "id": "86d6a8ac"
   },
   "outputs": [],
   "source": [
    "#create table with manually corrected wwtps to later add UP_ID_NOTE column to treatment train assignment dataframe\n",
    "manual_check_ups = uplist_eicodes[['CWNS_NUM','UP_ID_NOTE']]\n",
    "manual_check_ups = manual_check_ups.dropna()\n",
    "manual_check_ups = manual_check_ups.drop_duplicates(subset = 'CWNS_NUM')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2789de7f",
   "metadata": {
    "id": "2789de7f"
   },
   "source": [
    "# Define functions for treatment train assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f9e052",
   "metadata": {
    "id": "f7f9e052"
   },
   "outputs": [],
   "source": [
    "def clear_old_treatment(uplist_yr_table, scenario):\n",
    "  '''\n",
    "  Function that removes outdated secondary/solids processes from cumulative unit process list\n",
    "    Parameters:\n",
    "      uplist_yr_table = dataframe of all reported unit processes relevant to treatment train assignment\n",
    "      scenario = scenario for treatment train assignment (e.g. 2022_MIN = treatment trains anticipated to have been active in 2022)\n",
    "    Returns:\n",
    "      uplist_werf_yr_final = modified dataframe of reported unit processes relevant to treatment train assignment, excluding old secondary/solids treatment processes\n",
    "  '''\n",
    "  #extract all solids treatment processes from cumulative unit process list\n",
    "  uplist_yr_table_dig = uplist_yr_table.loc[(uplist_yr_table['WERF_CODE'] == 'AED') | (uplist_yr_table['WERF_CODE'] == 'AND') | (uplist_yr_table['WERF_CODE'] == 'LIME') | (uplist_yr_table['WERF_CODE'] == 'FBI') | (uplist_yr_table['WERF_CODE'] == 'MHI') | (uplist_yr_table['WERF_CODE'] == 'BIODRY') | (uplist_yr_table['WERF_CODE'] == 'BS_LAGOON')]\n",
    "\n",
    "  #identify facilities with more than one reported solids process\n",
    "  uplist_yr_table_dig['DUP'] = uplist_yr_table_dig.duplicated(subset = 'CWNS_NUM', keep = False)\n",
    "  uplist_yr_table_dig_dup = uplist_yr_table_dig.loc[(uplist_yr_table_dig['DUP'] == True)]\n",
    "\n",
    "  #identify most recently reported solids process\n",
    "  up_werf_dig_dup_maxyr = uplist_yr_table_dig_dup.groupby(['CWNS_NUM'])['REPORT_YEAR'].describe()[['max']]\n",
    "  uplist_yr_table_dig_dup_keep = pd.merge(left = uplist_yr_table_dig_dup, right = up_werf_dig_dup_maxyr, how = 'left', on = 'CWNS_NUM')\n",
    "  uplist_yr_table_dig_dup_keep.loc[(uplist_yr_table_dig_dup_keep['REPORT_YEAR'] == uplist_yr_table_dig_dup_keep['max']), 'KEEP'] = 1\n",
    "  uplist_yr_table_dig_dup_keep.loc[(uplist_yr_table_dig_dup_keep['REPORT_YEAR'] != uplist_yr_table_dig_dup_keep['max']), 'KEEP'] = 0\n",
    "  uplist_yr_table_dig_dup_keep = uplist_yr_table_dig_dup_keep.loc[:,['CWNS_NUM','REPORT_YEAR','WERF_CODE','KEEP']]\n",
    "  uplist_yr_table_dig_dup_keep.sort_values(by = ['CWNS_NUM','REPORT_YEAR'], ascending=False, inplace=True, ignore_index=True)\n",
    "\n",
    "  #remove less recently reported solids processes from cumulative unit process list\n",
    "  uplist_werf_yr_cut = pd.merge(left = uplist_yr_table, right = uplist_yr_table_dig_dup_keep, how = 'left', on = ['CWNS_NUM','REPORT_YEAR','WERF_CODE'])\n",
    "  uplist_werf_yr_cut = uplist_werf_yr_cut.loc[:,['CWNS_NUM','REPORT_YEAR',f\"{scenario}_IND\",'WERF_CODE','KEEP']]\n",
    "  uplist_werf_yr = uplist_werf_yr_cut.loc[(uplist_werf_yr_cut['KEEP'] != 0)]\n",
    "  uplist_werf_yr = uplist_werf_yr.loc[:,['CWNS_NUM','REPORT_YEAR',f\"{scenario}_IND\",'WERF_CODE']]\n",
    "\n",
    "  #extract all secondary treatment processes from cumulative unit process list, excluding biogas utilization, biosolids lagoons, and polishing lagoons\n",
    "  uplist_werf_yr_sec = uplist_werf_yr.loc[(uplist_werf_yr['WERF_CODE'].str.contains('AS')) | (uplist_werf_yr['WERF_CODE'].str.contains('TF')) | (uplist_werf_yr['WERF_CODE'].str.contains('POND')) | (uplist_werf_yr['WERF_CODE'].str.contains('LAGOON'))]\n",
    "  uplist_werf_yr_sec = uplist_werf_yr_sec.loc[(uplist_werf_yr_sec['WERF_CODE'] != 'BIOGAS_CWNS')]\n",
    "  uplist_werf_yr_sec = uplist_werf_yr_sec.loc[(uplist_werf_yr_sec['WERF_CODE'] != 'BS_LAGOON')]\n",
    "  uplist_werf_yr_sec = uplist_werf_yr_sec.loc[(uplist_werf_yr_sec['WERF_CODE'] != 'LAGOON_POL')]\n",
    "\n",
    "  #identify facilities with more than one reported secondary process\n",
    "  uplist_werf_yr_sec['DUP'] = uplist_werf_yr_sec.duplicated(subset = 'CWNS_NUM', keep=False)\n",
    "  uplist_werf_yr_sec_dup = uplist_werf_yr_sec.loc[(uplist_werf_yr_sec['DUP'] == True)]\n",
    "\n",
    "  #identify most recently reported secondary process\n",
    "  up_werf_sec_dup_maxyr = uplist_werf_yr_sec_dup.groupby(['CWNS_NUM'])['REPORT_YEAR'].describe()[['max']]\n",
    "  uplist_werf_yr_sec_dup_keep = pd.merge(left = uplist_werf_yr_sec_dup, right = up_werf_sec_dup_maxyr, how = 'left', on = 'CWNS_NUM')\n",
    "  uplist_werf_yr_sec_dup_keep.loc[(uplist_werf_yr_sec_dup_keep['REPORT_YEAR'] == uplist_werf_yr_sec_dup_keep['max']), 'KEEP'] = 1\n",
    "  uplist_werf_yr_sec_dup_keep.loc[(uplist_werf_yr_sec_dup_keep['REPORT_YEAR'] != uplist_werf_yr_sec_dup_keep['max']), 'KEEP'] = 0\n",
    "  uplist_werf_yr_sec_dup_keep = uplist_werf_yr_sec_dup_keep.loc[:,['CWNS_NUM','REPORT_YEAR','WERF_CODE','KEEP']]\n",
    "  uplist_werf_yr_sec_dup_keep.sort_values(by = ['CWNS_NUM','REPORT_YEAR'], ascending = False, inplace = True, ignore_index = True)\n",
    "\n",
    "  #remove less recently reported secondary processes from cumulative unit process list\n",
    "  uplist_werf_yr_cut2 = pd.merge(left = uplist_werf_yr, right = uplist_werf_yr_sec_dup_keep, how = 'left', left_on = ['CWNS_NUM', 'REPORT_YEAR', 'WERF_CODE'], right_on = ['CWNS_NUM','REPORT_YEAR','WERF_CODE'])\n",
    "  uplist_werf_yr_cut2 = uplist_werf_yr_cut2.loc[:,['CWNS_NUM','REPORT_YEAR',f\"{scenario}_IND\",'WERF_CODE','KEEP']]\n",
    "  uplist_werf_yr_cut2 = uplist_werf_yr_cut2.loc[(uplist_werf_yr_cut2['KEEP'] != 0)]\n",
    "  uplist_werf_yr_final = uplist_werf_yr_cut2.loc[:,['CWNS_NUM','REPORT_YEAR',f\"{scenario}_IND\",'WERF_CODE']]\n",
    "  uplist_werf_yr_final.drop_duplicates(subset = ['CWNS_NUM','WERF_CODE'], inplace=True, ignore_index=True)\n",
    "\n",
    "  return uplist_werf_yr_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fce25f",
   "metadata": {
    "id": "f1fce25f"
   },
   "outputs": [],
   "source": [
    "def unit_process_pivot(uplist_werf_yr_to_pivot, scenario):\n",
    "  '''\n",
    "  Function that groups unit processes treated equivalently in Tarallo et al., 2015, then converts cumulative unit process list into a pivot table\n",
    "    Parameters:\n",
    "      uplist_werf_yr_to_pivot = cumulative unit process list\n",
    "      scenario = scenario for treatment train assignment (e.g. 2022_MIN = treatment trains anticipated to have been active in 2022)\n",
    "    Returns:\n",
    "      tt_uppvt_yr = pivot table of active unit processes in 2022 for each wastewater treatment plant, grouped when applicable\n",
    "  '''\n",
    "\n",
    "  #create pivot table of unit processes\n",
    "  tt_uppvt_yr = pd.pivot_table(uplist_werf_yr_to_pivot, index = 'CWNS_NUM', values = \"%s_IND\" %scenario, columns = 'WERF_CODE', aggfunc = np.sum, fill_value = 0)\n",
    "\n",
    "  #add empty columns for unit processes that were not reported in selected year\n",
    "  all_ups = up_eicodes['WERF_CODE'].unique()\n",
    "  reported_ups = uplist_werf_yr_to_pivot['WERF_CODE'].unique()\n",
    "  for up in all_ups:\n",
    "    if up not in reported_ups:\n",
    "      tt_uppvt_yr[up] = 0\n",
    "\n",
    "  #group conventional activated sludge without nutrient removal\n",
    "  tt_uppvt_yr['SUM_AS'] = tt_uppvt_yr['AS'] + tt_uppvt_yr['AS-A2O'] + tt_uppvt_yr['AS-BDENIT'] + tt_uppvt_yr['AS-EA'] + tt_uppvt_yr['AS-P'] + tt_uppvt_yr['AS-PUREO'] + tt_uppvt_yr['AS-SA']\n",
    "  tt_uppvt_yr['BASIC_AS'] = tt_uppvt_yr['AS'] + tt_uppvt_yr['AS-EA'] + tt_uppvt_yr['AS-SA'] + tt_uppvt_yr['AS-OD'] + tt_uppvt_yr['AS-SBR']\n",
    "  tt_uppvt_yr.loc[tt_uppvt_yr['BASIC_AS'] > 0, 'BASIC_AS'] = 1\n",
    "\n",
    "  #group all activated sludge with nitrogen removal\n",
    "  tt_uppvt_yr['AS_BNR_N'] = tt_uppvt_yr['AS-A2O'] + tt_uppvt_yr['AS-BDENIT']\n",
    "  tt_uppvt_yr.loc[tt_uppvt_yr['AS_BNR_N'] > 0, 'AS_BNR_N'] = 1\n",
    "  tt_uppvt_yr.loc[(tt_uppvt_yr['AS'] + tt_uppvt_yr['BNR']) > 1, 'AS_BNR_N'] = 1\n",
    "\n",
    "  #group all trickling filters\n",
    "  tt_uppvt_yr['TF_ALL'] = tt_uppvt_yr['TF'] + tt_uppvt_yr['TF-BF'] + tt_uppvt_yr['TF-RBC']\n",
    "  tt_uppvt_yr.loc[tt_uppvt_yr['TF_ALL'] > 0, 'TF_ALL'] = 1\n",
    "\n",
    "  #group all biological phosphorous removal\n",
    "  tt_uppvt_yr.loc[(((tt_uppvt_yr['SUM_AS'] > 0) & (tt_uppvt_yr['BIO-P'] > 0)) | (tt_uppvt_yr['AS-P'] == 1)), 'AS_BNR_P'] = 1\n",
    "\n",
    "  #override multiple entries to just one\n",
    "  tt_uppvt_yr.loc[tt_uppvt_yr['PRIMARY'] > 0, 'PRIMARY'] = 1\n",
    "  tt_uppvt_yr.loc[tt_uppvt_yr['MHI'] > 0, 'MHI'] = 1\n",
    "  tt_uppvt_yr.loc[tt_uppvt_yr['BDENIT'] > 0, 'BDENIT'] = 1\n",
    "\n",
    "  #drop unnecessary columns and fill nan values with zero\n",
    "  tt_uppvt_yr = tt_uppvt_yr.drop(['DEWATER', 'DISINF','DISINF-UV','LAGOON_POL'], axis = 1)\n",
    "  tt_uppvt_yr = tt_uppvt_yr.fillna(0)\n",
    "\n",
    "  #add column with the total number of unit processes used for each wwtp\n",
    "  tt_uppvt_yr['COUNT_UP'] = tt_uppvt_yr['AED'] + tt_uppvt_yr['AND'] + tt_uppvt_yr['BASIC_AS'] + tt_uppvt_yr['AS_BNR_N'] + tt_uppvt_yr['BDENIT'] + tt_uppvt_yr['AS_BNR_P'] + tt_uppvt_yr['BIODRY'] + tt_uppvt_yr['BIOGAS_CWNS'] + tt_uppvt_yr['BNIT'] + tt_uppvt_yr['BNR'] + tt_uppvt_yr['BS_LAGOON'] + tt_uppvt_yr['CHEM-P'] + tt_uppvt_yr['DISINF-O3'] + tt_uppvt_yr['FBI'] + tt_uppvt_yr['LAGOON'] + tt_uppvt_yr['LAGOON_AER'] + tt_uppvt_yr['LAGOON_ANAER'] + tt_uppvt_yr['LAGOON_FAC'] + tt_uppvt_yr['LAND_TRT'] + tt_uppvt_yr['LIME'] + tt_uppvt_yr['MBR-BNR'] + tt_uppvt_yr['MHI'] + tt_uppvt_yr['NIT'] + tt_uppvt_yr['STBL_POND'] + tt_uppvt_yr['TF_ALL']\n",
    "\n",
    "  return tt_uppvt_yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ap1mQTFRcLqP",
   "metadata": {
    "id": "Ap1mQTFRcLqP"
   },
   "outputs": [],
   "source": [
    "def treatment_train_werf(tt_upadd_yr, bgyr):\n",
    "  '''\n",
    "  Function that assigns wastewater treatment facilities with enough unit process information one or more treatment trains\n",
    "    Parameters:\n",
    "      tt_upadd_yr = reported unit processes for each facility in pivot table form\n",
    "      bgyr = year which biogas systems for electricity generation are confirmed to be active\n",
    "    Returns:\n",
    "      tt_werf_yr = dataframe with treatment train assignments for each facility that has sufficient unit process information\n",
    "  '''\n",
    "\n",
    "  tt_werf_yr = tt_upadd_yr\n",
    "\n",
    "  def assign(name, check, exceptions=[]):\n",
    "    '''\n",
    "    Core function which assigns a treatment train if a subset of key unit processes has been reported in CWNS\n",
    "      Parameters:\n",
    "        name: treatment train to be assigned, written in Tarallo et al., 2015 naming convention\n",
    "        check: unit processes that have to be present in order for treatment train to be assigned\n",
    "        exceptions: unit processes and/or treatment trains that must be absent/not yet assigned in order for treatment train to be assigned\n",
    "      Returns:\n",
    "        tt_werf_yr = dataframe with treatment train assignments for each facility that has sufficient unit process information\n",
    "    '''\n",
    "    #sum the number of key unit processes present within check for a given treatment train\n",
    "    #for given treatment train, set value equal to the sum above\n",
    "    tt_werf_yr[name] = sum(tt_werf_yr[check[i]] for i in range(len(check)))\n",
    "\n",
    "    #if sum of relevant unit processes is not equal to the number of key unit processes in check, turn off treatment train\n",
    "    tt_werf_yr.loc[tt_werf_yr[name] != len(check), name] = 0\n",
    "\n",
    "    #if sum of relevant unit processes is equal to the number of key unit processes in check, turn on treatment train\n",
    "    tt_werf_yr.loc[tt_werf_yr[name] == len(check), name] = 1\n",
    "\n",
    "    #if exceptions exist, iterate through exceptions and turn treatment train off if one or more exceptions is met\n",
    "    if len(exceptions) > 0:\n",
    "        for exception in exceptions:\n",
    "            tt_werf_yr.loc[tt_werf_yr[exception] == 1, name] = 0\n",
    "\n",
    "    return tt_werf_yr\n",
    "\n",
    "  #check treatment trains sequentially and assign if all key unit processes exist and excepting unit processes/trains do not\n",
    "\n",
    "  #membrane bioreactor trains\n",
    "  assign('N1E', ['MBR-BNR','AND',f'BIOGAS_EL_{bgyr}'])\n",
    "  assign('N1', ['MBR-BNR','AND'],['N1E'])\n",
    "  assign('N2', ['MBR-BNR','AED'])\n",
    "\n",
    "  #uncomment code below if ENR is identified in cumulative unit process list\n",
    "  # assign('M1', ['AS','AND','ENR','CHEM-P']),\n",
    "  # assign('L1', ['AS','AND','ENR'])\n",
    "\n",
    "  #biological and chemical phosphorus removal trains- priority 1 within activated sludge assignment\n",
    "  assign('H1E', ['AS_BNR_P','AND','CHEM-P',f'BIOGAS_EL_{bgyr}'])\n",
    "  assign('H1', ['AS_BNR_P','AND','CHEM-P'],['H1E'])\n",
    "\n",
    "  #biological phosphorus removal trains- priority 2 in activated sludge assignment\n",
    "  #G train not assigned if an H train has already been assigned\n",
    "  assign('G6', ['AS_BNR_P','FBI'])\n",
    "  assign('G5', ['AS_BNR_P','MHI'])\n",
    "  assign('G3', ['AS_BNR_P','LIME'])\n",
    "  assign('G2', ['AS_BNR_P','AED'])\n",
    "  assign('G1E', ['AS_BNR_P','AND',f'BIOGAS_EL_{bgyr}'],['H1E','H1'])\n",
    "  assign('G1', ['AS_BNR_P','AND'], ['G1E','H1E','H1'])\n",
    "\n",
    "  #biological nitrogen removal trains- priority 3 in assignment\n",
    "  #I train not assigned if H or G train has already been assigned\n",
    "  assign('I6', ['AS_BNR_N','FBI'],['G6'])\n",
    "  assign('I5', ['AS_BNR_N','MHI'],['G5'])\n",
    "  assign('I3', ['AS_BNR_N','LIME'],['G3'])\n",
    "  assign('I2', ['AS_BNR_N','AED'],['G2'])\n",
    "  assign('I1E', ['AS_BNR_N','AND',f'BIOGAS_EL_{bgyr}'],['H1','H1E','G1','G1E'])\n",
    "  assign('I1', ['AS_BNR_N','AND'], ['I1E','H1','H1E','G1','G1E'])\n",
    "\n",
    "  #nitrification trains- priority 3 in assignment\n",
    "  #F/E trains not assigned if H, G, or I train has already been assigned\n",
    "  assign('F1E', ['BASIC_AS','AND','NIT',f'BIOGAS_EL_{bgyr}'], ['AS_BNR_N','G1','G1E','H1','H1E','I1','I1E'])\n",
    "  assign('F1', ['BASIC_AS','AND','NIT'], ['AS_BNR_N','F1E','G1','G1E','H1','H1E','I1','I1E'])\n",
    "  assign('E2P', ['BASIC_AS','AED','NIT','PRIMARY'], ['AS_BNR_N','G2','I2'])\n",
    "  assign('E2', ['BASIC_AS','AED','NIT'], ['AS_BNR_N','G2','I2','E2P'])\n",
    "\n",
    "  #pure oxygen activated sludge trains- priority 4 in activated sludge assignment\n",
    "  #O train not assigned if E, F, H, G, or I train has already been assigned\n",
    "  assign('O5', ['AS-PUREO','MHI'],['G5','I5'])\n",
    "  assign('O6', ['AS-PUREO','FBI'],['G6','I6'])\n",
    "  assign('O3', ['AS-PUREO','LIME'],['G3','I3'])\n",
    "  assign('O2', ['AS-PUREO','AED'],['G2','I2','E2','E2P'])\n",
    "  assign('O1E', ['AS-PUREO','AND',f'BIOGAS_EL_{bgyr}'],['F1','F1E','G1E','G1','I1','I1E','H1','H1E'])\n",
    "  assign('O1', ['AS-PUREO','AND'], ['F1','F1E','O1E','G1E','G1','I1','I1E','H1','H1E'])\n",
    "\n",
    "  #trickling filter trains\n",
    "  #D train assignment can exist in multiple treatment trains alongside activated sludge systems\n",
    "  assign('D5', ['TF_ALL','MHI'])\n",
    "  assign('D6', ['TF_ALL','FBI'])\n",
    "  assign('D3', ['TF_ALL','LIME'])\n",
    "  assign('D2', ['TF_ALL','AED'])\n",
    "  assign('D1E', ['TF_ALL','AND',f'BIOGAS_EL_{bgyr}'])\n",
    "  assign('D1', ['TF_ALL','AND'],['D1E'])\n",
    "\n",
    "  #basic activated sludge, primary trains- priority 5 in activated sludge assignment\n",
    "  #B train not assigned if O, E, F, H, G, or I train has already been assigned\n",
    "  assign('B6', ['BASIC_AS','FBI','PRIMARY'], ['G6','I6','O6'])\n",
    "  assign('B5', ['BASIC_AS','MHI','PRIMARY'], ['AS-PUREO','G5','I5','O5'])\n",
    "  assign('B4', ['BASIC_AS','AND','BIODRY','PRIMARY'])\n",
    "  assign('B3', ['BASIC_AS','LIME','PRIMARY'], ['G3','I3','O3'])\n",
    "  assign('B2', ['BASIC_AS','AED','PRIMARY'], ['E2','E2P','G2','I2','N2','O2'])\n",
    "  assign('B1E', ['BASIC_AS','AND','PRIMARY',f'BIOGAS_EL_{bgyr}'],['AS_BNR_N','AS-PUREO','B4','F1','F1E','G1','G1E','H1','H1E','I1','I1E','N1','N1E','O1','O1E'])\n",
    "  assign('B1', ['BASIC_AS','AND','PRIMARY'], ['AS_BNR_N','AS-PUREO','B1E','B4','F1','F1E','G1','G1E','H1','H1E','I1','I1E','N1','N1E','O1','O1E'])\n",
    "\n",
    "  #basic activated sludge trains- priority 6 in activated sludge assignment\n",
    "  #B train not assigned if B, O, E, F, H, G, or I train has already been assigned\n",
    "  assign('C5', ['BASIC_AS','MHI'], ['B5','G5','I5','O5'])\n",
    "  assign('C6', ['BASIC_AS','FBI'], ['B6','G6','I6','O6'])\n",
    "  assign('C3', ['BASIC_AS','LIME'], ['B3','G3','I3','O3'])\n",
    "  assign('C2', ['BASIC_AS','AED'], ['B2','E2','E2P','G2','I2','N2','O2'])\n",
    "  assign('C1E', ['BASIC_AS','AND',f'BIOGAS_EL_{bgyr}'], ['B1','B1E','B4','F1','F1E','G1','G1E','H1','H1E','I1E','I1','N1E','N1','O1','O1E'])\n",
    "  assign('C1', ['BASIC_AS','AND'], ['B1','B1E','B4','C1E','F1','F1E','G1','G1E','H1','H1E','I1','I1E','N1','N1E','O1','O1E'])\n",
    "\n",
    "  #identify the number of treatment trains assigned for each facility in the first round of assignment\n",
    "  tt_werf_yr['TT_IDENTIFIED'] = sum(tt_werf_yr[i] for i in ('LAGOON','LAGOON_AER','LAGOON_ANAER','LAGOON_FAC',\n",
    "                                                            'STBL_POND','I1E','G6','I6',\n",
    "                                                            'O5','O6','O3','O1E','G5',\n",
    "                                                            'I5','C5','C6','O2','O1',\n",
    "                                                            'N1','N1E','N2','I3','I2','I1',\n",
    "                                                            'H1','H1E','G3','G2','G1','G1E',\n",
    "                                                            'F1','F1E','E2','E2P','D5','D6',\n",
    "                                                            'D1','D1E','D3','D2','C3','C2',\n",
    "                                                            'C1','C1E','B6','B5','B4','B3',\n",
    "                                                            'B1E','B1','B2'))\n",
    "\n",
    "  #for treatment trains that were identified using reported unit processes, add a note\n",
    "  tt_werf_yr.loc[tt_werf_yr['TT_IDENTIFIED'] > 0, 'TT_ASSIGN_NOTE'] = 'Assigned based on reported unit processes'\n",
    "\n",
    "  return tt_werf_yr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PdWe7FtFd8lG",
   "metadata": {
    "id": "PdWe7FtFd8lG"
   },
   "source": [
    "# Assign treatment trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b15c46a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8627,
     "status": "ok",
     "timestamp": 1746640566587,
     "user": {
      "displayName": "Abigayle Hodson",
      "userId": "02880304820331263887"
     },
     "user_tz": 420
    },
    "id": "7b15c46a",
    "outputId": "f1adf988-b3c2-4890-a49d-dc6f13c78b9e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-110-a80931cb9198>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  uplist_yr_table_dig['DUP'] = uplist_yr_table_dig.duplicated(subset = 'CWNS_NUM', keep = False)\n",
      "<ipython-input-111-1898439fa410>:12: FutureWarning: The provided callable <function sum at 0x7f129510cf40> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  tt_uppvt_yr = pd.pivot_table(uplist_werf_yr_to_pivot, index = 'CWNS_NUM', values = \"%s_IND\" %scenario, columns = 'WERF_CODE', aggfunc = np.sum, fill_value = 0)\n",
      "<ipython-input-111-1898439fa410>:12: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  tt_uppvt_yr = pd.pivot_table(uplist_werf_yr_to_pivot, index = 'CWNS_NUM', values = \"%s_IND\" %scenario, columns = 'WERF_CODE', aggfunc = np.sum, fill_value = 0)\n"
     ]
    }
   ],
   "source": [
    "#filter unit process list to unit processes that were present in 2022- includes plants with reported processes from 2004, 2008, 2012, and 2022 CWNS\n",
    "uplist_werf_2022 = uplist_eicodes[['CWNS_NUM','REPORT_YEAR','2022_MIN_IND','WERF_CODE']]\n",
    "uplist_werf_2022 = uplist_werf_2022.loc[(uplist_werf_2022['2022_MIN_IND'] == 1)]\n",
    "uplist_werf_2022 = uplist_werf_2022.dropna(subset = ['WERF_CODE'])\n",
    "uplist_werf_2022.sort_values(by = ['CWNS_NUM','REPORT_YEAR'], ascending = True, inplace = True, ignore_index = True)\n",
    "\n",
    "#retain only most recently reported secondary/solids processes\n",
    "uplist_werf_2022_final = clear_old_treatment(uplist_werf_2022, '2022_MIN')\n",
    "\n",
    "#create a pivot table describing all the unit processes at a certain wwtp in 2022\n",
    "tt_uppvt_2022 = unit_process_pivot(uplist_werf_2022_final,'2022_MIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa499b7",
   "metadata": {
    "id": "daa499b7"
   },
   "outputs": [],
   "source": [
    "#filter main wwtp dataframe to relevant columns\n",
    "wwtps_trt_2022 = wwtps[['CWNS_NUM','PRES_AMMONIA_REMOVAL','PRES_NITROGEN_REMOVAL','PRES_PHOSPHOROUS_REMOVAL','BIOGAS_EL_2022','FLOW_2022_MGD','2022_FLOW_CAT_MGD','EPA_REGION']]\n",
    "\n",
    "#merge unit process list and facility info tables; replace nan values with 0\n",
    "tt_upadd_2022 = pd.merge(left = tt_uppvt_2022, right = wwtps_trt_2022, how = 'right', on = 'CWNS_NUM')\n",
    "tt_upadd_2022 = tt_upadd_2022.fillna(0)\n",
    "\n",
    "#use the ammonia/nitrogen/phosphorous removal flags provided in the 2004, 2008, and 2012 CWNS to add nutrient removal processes to unit process list\n",
    "#NIT_FLAG column is just used for tracking which nitrification unit processes were added via the PRES_AMMONIA_REMOVAL column\n",
    "tt_upadd_2022.loc[tt_upadd_2022['PRES_AMMONIA_REMOVAL'] == 'Y', \"NIT\"] = 1\n",
    "tt_upadd_2022.loc[tt_upadd_2022['PRES_AMMONIA_REMOVAL'] == 'Y', \"NIT_FLAG\"] = 1\n",
    "tt_upadd_2022.loc[tt_upadd_2022['PRES_NITROGEN_REMOVAL'] == 'Y', 'BNR'] = 1\n",
    "tt_upadd_2022.loc[tt_upadd_2022['PRES_PHOSPHOROUS_REMOVAL'] == 'Y', 'P_REMOVAL'] = 1\n",
    "\n",
    "#assume all phosphorus removal not specified as biological is done using chemical processes\n",
    "tt_upadd_2022.loc[(tt_upadd_2022['AS_BNR_P'] == 0) & (tt_upadd_2022['BIO-P'] == 0) & (tt_upadd_2022['P_REMOVAL'] == 1), 'CHEM-P'] = 1\n",
    "\n",
    "#filter to relevant columns\n",
    "tt_upadd_2022 = tt_upadd_2022[['CWNS_NUM','AED','AND','AS','AS-A2O','AS-BDENIT','AS-EA','AS-OD','AS-P','AS-PUREO','AS-SA','AS-SBR','BDENIT','BIO-P','BIODRY','BIOGAS_CWNS','BNIT','BNR','BS_LAGOON','CHEM-P','DISINF-O3','FBI','LAGOON','LAGOON_AER','LAGOON_ANAER','LAGOON_FAC','LAND_TRT','LIME','MBR-BNR','MHI','NIT','NIT_FLAG','PRIMARY','STBL_POND','TF','TF-BF','TF-RBC','SUM_AS','TF_ALL','BASIC_AS','AS_BNR_N','AS_BNR_P','COUNT_UP','BIOGAS_EL_2022','FLOW_2022_MGD','2022_FLOW_CAT_MGD','EPA_REGION']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9ce035",
   "metadata": {
    "collapsed": true,
    "id": "ee9ce035",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for wwtps with sufficient unit process data, assign treatment trains and filter to relevant columns\n",
    "ttwerf_2022 = treatment_train_werf(tt_upadd_2022, 2022)\n",
    "ttwerf_2022 = ttwerf_2022.loc[:,['CWNS_NUM','AED','AND','AS','AS-A2O','AS-BDENIT','AS-EA','AS-OD','AS-P','AS-PUREO','AS-SA','AS-SBR','BDENIT','BIO-P','BIODRY','BIOGAS_CWNS','BNIT','BNR','BS_LAGOON','CHEM-P','DISINF-O3','FBI','LAGOON','LAGOON_AER','LAGOON_ANAER','LAGOON_FAC','LAND_TRT','LIME','MBR-BNR','MHI','NIT','NIT_FLAG','PRIMARY','STBL_POND','TF','TF-BF','TF-RBC','SUM_AS','TF_ALL','BASIC_AS','AS_BNR_N','AS_BNR_P','COUNT_UP','BIOGAS_EL_2022','FLOW_2022_MGD','2022_FLOW_CAT_MGD','EPA_REGION','C1','C1E','C2','C3','C5','C6','B1','B1E','B2','B3','B4','B5','B6','D1','D1E','D2','D3','D5','D6','E2','E2P','F1','F1E','G1','G1E','G2','G3','G5','G6','H1','H1E','I1','I1E','I2','I3','I5','I6','N1','N1E','N2','O1','O1E','O2','O3','O5','O6','TT_IDENTIFIED','TT_ASSIGN_NOTE']]\n",
    "\n",
    "#for treatment O1 trains that have nitrification, switch to F1\n",
    "index = ttwerf_2022.loc[(ttwerf_2022['O1'] == 1) & (ttwerf_2022['NIT'] == 1)].index\n",
    "for i in index:\n",
    "  ttwerf_2022.at[i,'F1'] = 1\n",
    "  ttwerf_2022.at[i,'O1'] = 0\n",
    "\n",
    "#for treatment O1E trains that have nitrification, switch to F1E\n",
    "index2 = ttwerf_2022.loc[(ttwerf_2022['O1E'] == 1) & (ttwerf_2022['NIT'] == 1)].index\n",
    "for i in index2:\n",
    "  ttwerf_2022.at[i,'F1E'] = 1\n",
    "  ttwerf_2022.at[i,'O1E'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a50cca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1746640566920,
     "user": {
      "displayName": "Abigayle Hodson",
      "userId": "02880304820331263887"
     },
     "user_tz": 420
    },
    "id": "08a50cca",
    "outputId": "5c633442-5ec8-442f-d815-5102802b8fac",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-159-56f5a5ce0012>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tt_werf_2022_noid['ID_SECTRT'] = tt_werf_2022_noid['SUM_AS'] + tt_werf_2022_noid['TF_ALL'] + tt_werf_2022_noid['LAGOON']\n",
      "<ipython-input-159-56f5a5ce0012>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tt_werf_2022_noid['ID_SOLIDS'] = tt_werf_2022_noid['AED'] + tt_werf_2022_noid['AND'] + tt_werf_2022_noid['LIME'] + tt_werf_2022_noid['MHI'] + tt_werf_2022_noid['FBI']\n"
     ]
    }
   ],
   "source": [
    "#check for facilities that report both a secondary and solids treatment process that have not yet been assigned a treatment train\n",
    "tt_werf_2022_noid = ttwerf_2022.loc[(ttwerf_2022['TT_IDENTIFIED'] == 0) & (ttwerf_2022['COUNT_UP'] > 0)]\n",
    "tt_werf_2022_noid['ID_SECTRT'] = tt_werf_2022_noid['SUM_AS'] + tt_werf_2022_noid['TF_ALL'] + tt_werf_2022_noid['LAGOON']\n",
    "tt_werf_2022_noid['ID_SOLIDS'] = tt_werf_2022_noid['AED'] + tt_werf_2022_noid['AND'] + tt_werf_2022_noid['LIME'] + tt_werf_2022_noid['MHI'] + tt_werf_2022_noid['FBI']\n",
    "tt_werf_2022_noid2 = tt_werf_2022_noid.loc[(tt_werf_2022_noid['ID_SECTRT'] > 0) | (tt_werf_2022_noid['ID_SOLIDS'] > 0)]\n",
    "\n",
    "#assert statement failure indicates treatment_train_werf() function is not working correctly\n",
    "assert tt_werf_2022_noid2.loc[(tt_werf_2022_noid2['ID_SECTRT'] > 0) & (tt_werf_2022_noid2['ID_SOLIDS'] > 0)].shape[0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Vhi5fAPVQApN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1662,
     "status": "ok",
     "timestamp": 1746640568580,
     "user": {
      "displayName": "Abigayle Hodson",
      "userId": "02880304820331263887"
     },
     "user_tz": 420
    },
    "id": "Vhi5fAPVQApN",
    "outputId": "77bac7af-b239-4d87-8422-36a17bf261c7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-160-a4f9f878e62e>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  assigned['B1B1E'] = assigned['B1'] + assigned['B1E']\n",
      "<ipython-input-160-a4f9f878e62e>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  assigned['C1C1E'] = assigned['C1'] + assigned['C1E']\n",
      "<ipython-input-160-a4f9f878e62e>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  assigned['D1D1E'] = assigned['D1'] + assigned['D1E']\n",
      "<ipython-input-160-a4f9f878e62e>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  assigned['F1F1E'] = assigned['F1'] + assigned['F1E']\n",
      "<ipython-input-160-a4f9f878e62e>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  assigned['G1G1E'] = assigned['G1'] + assigned['G1E']\n",
      "<ipython-input-160-a4f9f878e62e>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  assigned['H1H1E'] = assigned['H1'] + assigned['H1E']\n",
      "<ipython-input-160-a4f9f878e62e>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  assigned['I1I1E'] = assigned['I1'] + assigned['I1E']\n",
      "<ipython-input-160-a4f9f878e62e>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  assigned['N1N1E'] = assigned['N1'] + assigned['N1E']\n",
      "<ipython-input-160-a4f9f878e62e>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  assigned['O1O1E'] = assigned['O1'] + assigned['O1E']\n",
      "<ipython-input-160-a4f9f878e62e>:51: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'I1I1E' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  most_common.at[index, 'Most Common TT (OVERALL)'] = row[row == row.max()].index.values[0]\n",
      "<ipython-input-160-a4f9f878e62e>:63: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'I1I1E' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  most_common.at[index, ('Most Common TT (' + key_up +')')] = row[relevant_tts][row[relevant_tts] == row[relevant_tts].max()].index.values[0]\n",
      "<ipython-input-160-a4f9f878e62e>:63: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'I1I1E' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  most_common.at[index, ('Most Common TT (' + key_up +')')] = row[relevant_tts][row[relevant_tts] == row[relevant_tts].max()].index.values[0]\n",
      "<ipython-input-160-a4f9f878e62e>:63: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'F1F1E' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  most_common.at[index, ('Most Common TT (' + key_up +')')] = row[relevant_tts][row[relevant_tts] == row[relevant_tts].max()].index.values[0]\n",
      "<ipython-input-160-a4f9f878e62e>:63: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'G1G1E' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  most_common.at[index, ('Most Common TT (' + key_up +')')] = row[relevant_tts][row[relevant_tts] == row[relevant_tts].max()].index.values[0]\n",
      "<ipython-input-160-a4f9f878e62e>:63: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'O2' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  most_common.at[index, ('Most Common TT (' + key_up +')')] = row[relevant_tts][row[relevant_tts] == row[relevant_tts].max()].index.values[0]\n",
      "<ipython-input-160-a4f9f878e62e>:63: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'O2' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  most_common.at[index, ('Most Common TT (' + key_up +')')] = row[relevant_tts][row[relevant_tts] == row[relevant_tts].max()].index.values[0]\n",
      "<ipython-input-160-a4f9f878e62e>:63: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'B5' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  most_common.at[index, ('Most Common TT (' + key_up +')')] = row[relevant_tts][row[relevant_tts] == row[relevant_tts].max()].index.values[0]\n",
      "<ipython-input-160-a4f9f878e62e>:63: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'F1F1E' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  most_common.at[index, ('Most Common TT (' + key_up +')')] = row[relevant_tts][row[relevant_tts] == row[relevant_tts].max()].index.values[0]\n",
      "<ipython-input-160-a4f9f878e62e>:63: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'D1D1E' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  most_common.at[index, ('Most Common TT (' + key_up +')')] = row[relevant_tts][row[relevant_tts] == row[relevant_tts].max()].index.values[0]\n",
      "<ipython-input-160-a4f9f878e62e>:63: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'B3' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  most_common.at[index, ('Most Common TT (' + key_up +')')] = row[relevant_tts][row[relevant_tts] == row[relevant_tts].max()].index.values[0]\n",
      "<ipython-input-160-a4f9f878e62e>:63: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'G6' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  most_common.at[index, ('Most Common TT (' + key_up +')')] = row[relevant_tts][row[relevant_tts] == row[relevant_tts].max()].index.values[0]\n"
     ]
    }
   ],
   "source": [
    "#based on the facilities that were assigned a treatment train based solely on reported unit process information, create a dataframe that contains both the most common treatment train overall and the most common treatment train with a key unit process present for all possible EPA region / plant size combinations. This dataframe is later used to make treatment train assignments for facilities with limited unit process information.\n",
    "\n",
    "#create a dataframe of all the wwtps that were assigned a treatment train based purely on reported unit processes\n",
    "assigned = ttwerf_2022.loc[ttwerf_2022['TT_IDENTIFIED'] != 0]\n",
    "assigned.reset_index(inplace = True, drop = True)\n",
    "\n",
    "#create combined columns for 1 and 1E trains\n",
    "assigned['B1B1E'] = assigned['B1'] + assigned['B1E']\n",
    "assigned['C1C1E'] = assigned['C1'] + assigned['C1E']\n",
    "assigned['D1D1E'] = assigned['D1'] + assigned['D1E']\n",
    "assigned['F1F1E'] = assigned['F1'] + assigned['F1E']\n",
    "assigned['G1G1E'] = assigned['G1'] + assigned['G1E']\n",
    "assigned['H1H1E'] = assigned['H1'] + assigned['H1E']\n",
    "assigned['I1I1E'] = assigned['I1'] + assigned['I1E']\n",
    "assigned['N1N1E'] = assigned['N1'] + assigned['N1E']\n",
    "assigned['O1O1E'] = assigned['O1'] + assigned['O1E']\n",
    "\n",
    "#filter to relevant columns\n",
    "assigned = assigned[['2022_FLOW_CAT_MGD', 'EPA_REGION', 'LAGOON','LAGOON_AER','LAGOON_ANAER','LAGOON_FAC','STBL_POND','C1C1E', 'C2', 'C3', 'C5',\n",
    "       'C6', 'B1B1E', 'B2', 'B3', 'B4', 'B5', 'B6', 'D1D1E', 'D2', 'D3', 'D5',\n",
    "       'D6', 'E2', 'E2P', 'F1F1E','G1G1E', 'G2', 'G3', 'G5', 'G6', 'H1H1E',\n",
    "       'I1I1E', 'I2', 'I3', 'I5', 'I6', 'N1N1E','N2', 'O1O1E', 'O2',\n",
    "       'O3', 'O5', 'O6']]\n",
    "\n",
    "#group assigned trains by EPA region and plant size\n",
    "most_common = assigned.groupby(['2022_FLOW_CAT_MGD', 'EPA_REGION']).sum()\n",
    "\n",
    "#create fields for the most common treatment train per EPA region / plant size overall and for just trains with key unit processes present\n",
    "most_common['Most Common TT (OVERALL)'] = np.nan\n",
    "most_common['Most Common TT (BASIC_AS)'] = np.nan\n",
    "most_common['Most Common TT (AS_BNR_N)'] = np.nan\n",
    "most_common['Most Common TT (AS-PUREO)'] = np.nan\n",
    "most_common['Most Common TT (AND)'] = np.nan\n",
    "most_common['Most Common TT (AED)'] = np.nan\n",
    "most_common['Most Common TT (LIME)'] = np.nan\n",
    "most_common['Most Common TT (FBI)'] = np.nan\n",
    "most_common['Most Common TT (MHI)'] = np.nan\n",
    "most_common['Most Common TT (TF_ALL)'] = np.nan\n",
    "most_common['Most Common TT (NIT)'] = np.nan\n",
    "most_common['Most Common TT (AS_BNR_P)'] = np.nan\n",
    "\n",
    "#define list of key unit processes and the treatment trains they are present within\n",
    "key_ups = {'BASIC_AS':['F1F1E','E2P','E2','B6','B5','B4','B3','B2','B1B1E','C5','C6','C3','C2','C1C1E'],'AS_BNR_N':['H1H1E','G6','G5','G3','G2','G1G1E'],'AS-PUREO':['O5','O6','O3','O2','O1O1E'],'AND':['O1O1E','N1N1E','H1H1E','G1G1E','I1I1E','F1F1E','D1D1E','B1B1E','C1C1E'],'AED':['O2','N2','G2','I2','E2P','E2','D2','B2','C2'],'LIME':['O3','G3','I3','D3','B3','C3'],'FBI':['O6','G6','I6','D6','B6','C6'],'MHI':['O5','G5','I5','D5','B5','C5'],'TF_ALL':['D5','D6','D3','D1D1E'],'NIT':['E2','E2P','F1F1E'], 'AS_BNR_P':['I6','I5','I3','I2','I1I1E']}\n",
    "\n",
    "#iterate through each EPA region / plant size combination\n",
    "for index, row in most_common.iterrows():\n",
    "  #identify most common treatment train for region / plant size\n",
    "  if row.max() != 0:\n",
    "    #if there are no ties for most common treatment train\n",
    "    if (row == row.max()).sum() == 1:\n",
    "      most_common.at[index, 'Most Common TT (OVERALL)'] = row[row == row.max()].index.values[0]\n",
    "    #if there are ties for the most common treatment train, separate with a slash\n",
    "    else:\n",
    "      most_common.at[index, 'Most Common TT (OVERALL)'] = '/'.join(row[row == row.max()].index.values.tolist())\n",
    "  #iterate through key unit processes\n",
    "  for key_up in key_ups:\n",
    "    #identify treatment trains that contain that key unit process\n",
    "    relevant_tts = key_ups[key_up]\n",
    "    #identify the most common treatment train within relevant subset\n",
    "    if row[relevant_tts].max() != 0:\n",
    "      #if there are no ties for most common treatment train\n",
    "      if (row[relevant_tts] == row[relevant_tts].max()).sum() == 1:\n",
    "        most_common.at[index, ('Most Common TT (' + key_up +')')] = row[relevant_tts][row[relevant_tts] == row[relevant_tts].max()].index.values[0]\n",
    "      #if there are ties for the most common treatment train, separate with a slash\n",
    "      else:\n",
    "        most_common.at[index, ('Most Common TT (' + key_up +')')] = '/'.join(row[relevant_tts][row[relevant_tts] == row[relevant_tts].max()].index.values.tolist())\n",
    "\n",
    "#if there are no facilities w/ key nutrient removal process in the size/region combination, override with most common treatment train containing key unit process across all EPA regions and size categories\n",
    "for index, row in most_common.iterrows():\n",
    "  for key_up in ['AS_BNR_P','NIT','AS_BNR_N']:\n",
    "    if pd.isna(row['Most Common TT (' + key_up +')']):\n",
    "      lst = list(most_common['Most Common TT (' + key_up +')'].dropna().values)\n",
    "      most_common.at[index, 'Most Common TT (' + key_up +')'] = max(set(lst), key=lst.count)\n",
    "\n",
    "#in the \"Most Common TT\" columns, replace B1B1E with B1, C1C1E with C1, etc. to ensure that electricity-producing trains are not assigned as most common trains\n",
    "most_common = most_common.replace({'B1B1E':'B1','C1C1E':'C1','D1D1E': 'D1','F1F1E': 'F1','G1G1E': 'G1','H1H1E': 'H1','I1I1E': 'I1','N1N1E':'N1','O1O1E':'O1'}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6lSHklYBsUlV",
   "metadata": {
    "id": "6lSHklYBsUlV"
   },
   "outputs": [],
   "source": [
    "#for unassigned treatment trains that contain key unit processes ('BASIC_AS, 'AS_BNR_N','AS_BNR_P','AS_PUREO','AND','AED','LIME','FBI','MHI','TF_ALL',and 'NIT'), assign a treatment train based on the most common train for that size/region that includes that key unit process\n",
    "\n",
    "#identify wwtps that do not yet have an assigned treatment train\n",
    "no_tt = ttwerf_2022.loc[ttwerf_2022['TT_IDENTIFIED'] == 0].reset_index(drop = True)\n",
    "\n",
    "#define list of key unit processes\n",
    "key_ups = ['BASIC_AS','AS_BNR_N','AS_BNR_P','AS-PUREO','AND','AED','LIME','FBI','MHI','TF_ALL','NIT']\n",
    "\n",
    "#for specific unit processes (AS_BNR_P, AS_BNR_N, NIT, AS_PUREO, BASIC_AS), if one is present, turn off less important unit processes\n",
    "#e.g., if AS_BNR_P is present, turn off AS_BNR_N, NIT, AS_PUREO, BASIC_AS; if AS_BNR_N is present, turn off NIT, AS_PUREO, BASIC_AS, etc.\n",
    "for index, row in no_tt.iterrows():\n",
    "  if row['AS_BNR_P'] == 1:\n",
    "    no_tt.at[index, 'AS_BNR_N'] = 0\n",
    "    no_tt.at[index, 'NIT'] = 0\n",
    "    no_tt.at[index, 'AS-PUREO'] = 0\n",
    "    no_tt.at[index, 'BASIC_AS'] = 0\n",
    "  elif row['AS_BNR_N'] == 1:\n",
    "    no_tt.at[index, 'NIT'] = 0\n",
    "    no_tt.at[index, 'AS-PUREO'] = 0\n",
    "    no_tt.at[index, 'BASIC_AS'] = 0\n",
    "  elif row['NIT'] == 1:\n",
    "    no_tt.at[index, 'AS-PUREO'] = 0\n",
    "    no_tt.at[index, 'BASIC_AS'] = 0\n",
    "  elif row['AS-PUREO'] == 1:\n",
    "    no_tt.at[index, 'BASIC_AS'] = 0\n",
    "\n",
    "#iterate through wwtps without an assigned treatment train\n",
    "for index, row in no_tt.iterrows():\n",
    "  #identify size and EPA region of current wwtp\n",
    "  size = row['2022_FLOW_CAT_MGD']\n",
    "  region = row['EPA_REGION']\n",
    "  #check for key unit processes in current wwtp\n",
    "  for up in key_ups:\n",
    "    if row[up] > 0:\n",
    "      #identify most common treatment train for plants of a similar size, region, and key unit process\n",
    "      tt_common = most_common.at[(size,region),('Most Common TT (' + up + ')')]\n",
    "      #turn on treatment train in no_tt dataframe\n",
    "      if pd.isna(tt_common) == False:\n",
    "        #if only one treatment train was identified\n",
    "        if '/' not in tt_common:\n",
    "          #if most common treatment train is a conventional activated sludge train, but the nitrification flag is on, override tt_common to nan\n",
    "          if (row['NIT'] == 1) & (tt_common[0] == 'B' or tt_common[0] == 'C'):\n",
    "            tt_common = np.nan\n",
    "          else:\n",
    "            no_tt.at[index, tt_common] = 1\n",
    "            no_tt.at[index, 'TT_IDENTIFIED'] = no_tt.at[index,'TT_IDENTIFIED'] + 1\n",
    "            no_tt.at[index, 'TT_ASSIGN_NOTE'] = 'Assigned based on partial unit process information based on common treatment trains of similar size in EPA region'\n",
    "        #if multiple treatment trains were identified, split into multiple strings before turning on treatment trains in no_tt dataframe\n",
    "        else:\n",
    "          tt_common_multiple = tt_common.split('/')\n",
    "          for tt in tt_common_multiple:\n",
    "            #if most common treatment train is a conventional activated sludge train, but the nitrification flag is on, override tt_common to nan\n",
    "            if (row['NIT'] == 1) & (tt[0] == 'B' or tt[0] == 'C'):\n",
    "              tt_common = np.nan\n",
    "            else:\n",
    "              no_tt.at[index, tt] = 1\n",
    "              no_tt.at[index, 'TT_IDENTIFIED'] = no_tt.at[index,'TT_IDENTIFIED'] + 1\n",
    "              no_tt.at[index, 'TT_ASSIGN_NOTE'] = 'Assigned based on partial unit process information based on common treatment trains of similar size in EPA region'\n",
    "\n",
    "#add original unit processes back into the no_tt dataframe\n",
    "original_ups = ttwerf_2022.loc[ttwerf_2022['TT_IDENTIFIED'] == 0].reset_index(drop = True)[['CWNS_NUM', 'AED', 'AND', 'AS', 'AS-A2O', 'AS-BDENIT',\n",
    "       'AS-EA', 'AS-OD', 'AS-P', 'AS-PUREO', 'AS-SA', 'AS-SBR', 'BDENIT',\n",
    "       'BIO-P', 'BIODRY', 'BIOGAS_CWNS', 'BNIT', 'BNR', 'BS_LAGOON', 'CHEM-P',\n",
    "       'DISINF-O3', 'FBI', 'LAGOON', 'LAGOON_AER', 'LAGOON_ANAER',\n",
    "       'LAGOON_FAC', 'LAND_TRT', 'LIME', 'MBR-BNR', 'MHI', 'NIT', 'NIT_FLAG',\n",
    "       'PRIMARY', 'STBL_POND', 'TF', 'TF-BF', 'TF-RBC', 'SUM_AS', 'TF_ALL',\n",
    "       'BASIC_AS', 'AS_BNR_N', 'AS_BNR_P']]\n",
    "\n",
    "new_tts = no_tt[['COUNT_UP', 'BIOGAS_EL_2022',\n",
    "       'FLOW_2022_MGD', '2022_FLOW_CAT_MGD', 'EPA_REGION', 'C1', 'C1E', 'C2',\n",
    "       'C3', 'C5', 'C6', 'B1', 'B1E', 'B2', 'B3', 'B4', 'B5', 'B6', 'D1',\n",
    "       'D1E', 'D2', 'D3', 'D5', 'D6', 'E2', 'E2P', 'F1', 'F1E', 'G1', 'G1E',\n",
    "       'G2', 'G3', 'G5', 'G6', 'H1', 'H1E', 'I1', 'I1E', 'I2', 'I3', 'I5',\n",
    "       'I6', 'N1', 'N1E', 'N2', 'O1', 'O1E', 'O2', 'O3', 'O5', 'O6',\n",
    "       'TT_IDENTIFIED', 'TT_ASSIGN_NOTE']]\n",
    "\n",
    "no_tt = pd.concat([original_ups, new_tts], axis = 1)\n",
    "\n",
    "#merge new assignments based on partial unit process information back into main dataframe\n",
    "ttwerf_2022 = ttwerf_2022.loc[ttwerf_2022['TT_IDENTIFIED'] != 0]\n",
    "ttwerf_2022 = pd.concat([ttwerf_2022, no_tt], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e18616",
   "metadata": {
    "id": "a1e18616"
   },
   "outputs": [],
   "source": [
    "#for remaining wwtps without a treatment train assignment, assign a treatment train using the most common treatment train of that size/region (ignoring production of energy from biogas)\n",
    "no_tt = ttwerf_2022.loc[ttwerf_2022['TT_IDENTIFIED'] == 0].reset_index(drop = True)\n",
    "\n",
    "#iterate through wwtps without an assigned treatment train\n",
    "for index, row in no_tt.iterrows():\n",
    "  #identify size and EPA region of current wwtp\n",
    "  size = row['2022_FLOW_CAT_MGD']\n",
    "  region = row['EPA_REGION']\n",
    "  #identify most common treatment train for plants of a similar size and region\n",
    "  tt_common = most_common.at[(size,region),('Most Common TT (OVERALL)')]\n",
    "  #turn on treatment train in no_tt dataframe\n",
    "  if pd.isna(tt_common) == False:\n",
    "    #if only one treatment train was identified\n",
    "    if '/' not in tt_common:\n",
    "      #if most common treatment train is a conventional activated sludge train, but the nitrification flag is on, override tt_common to nan\n",
    "      if (row['NIT'] == 1) & (tt_common[0] == 'B' or tt_common[0] == 'C'):\n",
    "        tt_common = np.nan\n",
    "      else:\n",
    "        no_tt.at[index, tt_common] = 1\n",
    "        no_tt.at[index, 'TT_IDENTIFIED'] = no_tt.at[index,'TT_IDENTIFIED'] + 1\n",
    "        no_tt.at[index, 'TT_ASSIGN_NOTE'] = 'Assigned based on common treatment trains of similar size in EPA region'\n",
    "    #if multiple treatment trains were identified, split into multiple strings before turning on treatment trains in no_tt dataframe\n",
    "    else:\n",
    "      tt_common_multiple = tt_common.split('/')\n",
    "      for tt in tt_common_multiple:\n",
    "        #if most common treatment train is a conventional activated sludge train, but the nitrification flag is on, override tt_common to nan\n",
    "        if (row['NIT'] == 1) & (tt[0] == 'B' or tt[0] == 'C'):\n",
    "          tt = np.nan\n",
    "        else:\n",
    "          no_tt.at[index, tt] = 1\n",
    "          no_tt.at[index, 'TT_IDENTIFIED'] = no_tt.at[index,'TT_IDENTIFIED'] + 1\n",
    "          no_tt.at[index, 'TT_ASSIGN_NOTE'] = 'Assigned based on common treatment trains of similar size in EPA region'\n",
    "\n",
    "#merge new assignments back into main dataframe\n",
    "ttwerf_2022 = ttwerf_2022.loc[ttwerf_2022['TT_IDENTIFIED'] != 0]\n",
    "ttwerf_2022 = pd.concat([ttwerf_2022, no_tt], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KtKDMzVpkhR_",
   "metadata": {
    "id": "KtKDMzVpkhR_"
   },
   "outputs": [],
   "source": [
    "#update the UP_ID_NOTE column to reflect manual unit process checks\n",
    "tt_werf_2022_final = pd.merge(left = ttwerf_2022, right = manual_check_ups, how = 'left', on = 'CWNS_NUM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mKSRQ3aDt1GA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2759,
     "status": "ok",
     "timestamp": 1746640572983,
     "user": {
      "displayName": "Abigayle Hodson",
      "userId": "02880304820331263887"
     },
     "user_tz": 420
    },
    "id": "mKSRQ3aDt1GA",
    "outputId": "a4e0adce-2629-4dfe-eb42-7313c6ffe9aa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-164-6d9613882418>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  biogas_tts.loc[biogas_tts['CWNS_NUM'] == wwtp, 'Assigned an E train?'] = 'Yes'\n",
      "<ipython-input-164-6d9613882418>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  biogas_tts['TT_ASSIGNED'] = np.nan\n",
      "<ipython-input-164-6d9613882418>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  biogas_tts['TT_ASSIGNED'] = biogas_tts['TT_ASSIGNED'].astype('object')\n"
     ]
    }
   ],
   "source": [
    "#identify facilities that reported using biogas to generate electricity in the DOE or WEF databases that were not assigned an electricity-generating treatment train\n",
    "biogas_tts = tt_werf_2022_final.loc[tt_werf_2022_final['BIOGAS_EL_2022'] == 1]\n",
    "biogas_tts.reset_index(inplace = True, drop = True)\n",
    "for wwtp in biogas_tts['CWNS_NUM']:\n",
    "   if biogas_tts.loc[biogas_tts['CWNS_NUM'] == wwtp][['C1E','B1E','D1E','F1E','H1E','N1E','I1E','G1E','O1E']].values.sum() > 0:\n",
    "      biogas_tts.loc[biogas_tts['CWNS_NUM'] == wwtp, 'Assigned an E train?'] = 'Yes'\n",
    "   else:\n",
    "      biogas_tts.loc[biogas_tts['CWNS_NUM'] == wwtp, 'Assigned an E train?'] = 'No'\n",
    "\n",
    "#create a column that contains which treatment train(s) a facility was assigned\n",
    "tts = ['LAGOON', 'LAGOON_AER','LAGOON_ANAER', 'LAGOON_FAC', 'STBL_POND', 'C1', 'C1E','C2', 'C3', 'C5', 'C6','B1', 'B1E', 'B2', 'B3', 'B4', 'B5', 'B6', 'D1', 'D1E','D2', 'D3', 'D5', 'D6','E2', 'E2P', 'F1', 'F1E','I1', 'I1E', 'I2', 'I3', 'I5', 'I6', 'G1', 'G1E','G2', 'G3', 'G5', 'G6', 'H1', 'H1E','N1', 'N1E','N2', 'O1', 'O1E', 'O2', 'O3', 'O5','O6']\n",
    "biogas_tts['TT_ASSIGNED'] = np.nan\n",
    "biogas_tts['TT_ASSIGNED'] = biogas_tts['TT_ASSIGNED'].astype('object')\n",
    "for row in range(0,biogas_tts.shape[0]):\n",
    "  tt_curr = []\n",
    "  for tt in tts:\n",
    "    if biogas_tts.iloc[row][tt] == 1:\n",
    "      tt_curr = tt_curr + [tt]\n",
    "  biogas_tts.at[row,'TT_ASSIGNED'] = tt_curr\n",
    "\n",
    "#for facilities that reported electricity generation but were not assigned an \"E\" train, override to the electricity-producing version of the treatment train\n",
    "override = biogas_tts.loc[((biogas_tts['TT_ASSIGN_NOTE'] == 'Assigned based on partial unit process information based on common treatment trains of similar size in EPA region') | (biogas_tts['TT_ASSIGN_NOTE'] == 'Assigned based on common treatment trains of similar size in EPA region')) & (biogas_tts['Assigned an E train?'] == 'No')].reset_index(drop = True)\n",
    "for index, row in override.iterrows():\n",
    "  tts = row['TT_ASSIGNED']\n",
    "  #if just one treatment train identified, switch to electricity-producing version of that train\n",
    "  if len(tts) == 1:\n",
    "    if tts[0] != 'E2P':\n",
    "      override.at[index, tts[0]] = 0\n",
    "      override.at[index, tts[0] + 'E'] = 1\n",
    "  #if multiple treatment trains were identified, switch to electricity-producing version of those trains\n",
    "  else:\n",
    "    for tt in tts:\n",
    "      if tts[0] != 'E2P':\n",
    "        override.at[index, tt] = 0\n",
    "        override.at[index, tt + 'E'] = 1\n",
    "\n",
    "#add new electricity-producing trains into main dataframe\n",
    "override.drop(columns = ['Assigned an E train?','TT_ASSIGNED'], inplace = True)\n",
    "tt_werf_2022_final = tt_werf_2022_final[~tt_werf_2022_final['CWNS_NUM'].isin(override['CWNS_NUM'])]\n",
    "tt_werf_2022_final = pd.concat([tt_werf_2022_final, override], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1t5lwYxTnfL2",
   "metadata": {
    "id": "1t5lwYxTnfL2"
   },
   "outputs": [],
   "source": [
    "#for facilities that reported using biogas to generate electricity, but were not assigned an electricity-producing train due to a lack of unit process information, manually correct treatment train assignment based on publicly available information\n",
    "#treatment train dataframe is corrected rather than the cumulative unit process list because it is simpler to identify facilities that need biogas corrections after treatment train assignment rather than before\n",
    "\n",
    "#Kitsap Co SD #7 WWTP; online checks show that wwtp has primary, activated sludge, anaerobic digestion, and nitrification\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '53002625501', 'STBL_POND'] = 0\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '53002625501', 'F1E'] = 1\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '53002625501', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n",
    "\n",
    "#NEW HAVEN EAST SHORE WPCF; online checks show that wwtp generates energy using incinerator\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '09000930003', 'B1E'] = 1\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '09000930003', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n",
    "\n",
    "#STEPHENSON WTP; online checks show that wwtp uses a trickling filter\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '26002047001', 'STBL_POND'] = 0\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '26002047001', 'D1E'] = 1\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '26002047001', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n",
    "\n",
    "#BUCKLIN PT STP; online checks show that wwtp has nitrogen removal and activated sludge\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '44000031001', 'LAGOON'] = 0\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '44000031001', 'I1E'] = 1\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '44000031001', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n",
    "\n",
    "#POCATELLO STP; online checks show that wwtp has ammonia and phosphorous removal\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '16000001001', 'LAGOON_AER'] = 1\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '16000001001', 'G1E'] = 1\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '16000001001', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n",
    "\n",
    "#Riverside WPCF; online checks show that wwtp uses membrane bioreactors\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '06008001001', 'STBL_POND'] = 0\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '06008001001', 'N1E'] = 1\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '06008001001', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n",
    "\n",
    "#Springfield SW WWTP; online checks show that wwtp uses chemical and biological phosphorus removal\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '29001026001', 'E2P'] = 0\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '29001026001', 'H1E'] = 1\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '29001026001', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024))'\n",
    "\n",
    "#RM Clayton WRP; online checks show that  wwtp uses membrane bioreactors\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '13000012004', 'LAGOON_ANAER'] = 0\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '13000012004', 'N1E'] = 1\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '13000012004', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n",
    "\n",
    "#Landis Sewerage Authority - CS/STP; online checks show that wwtp has nitrification and anaerobic digestion\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '34005051001', 'STBL_POND'] = 0\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '34005051001', 'F1E'] = 1\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '34005051001', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n",
    "\n",
    "#METROPOLITAN WWTP; online checks show that wwtp generates energy using incinerator\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '27000001001', 'G1E'] = 1\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '27000001001', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n",
    "\n",
    "#Davis, City of WWTP; online checks show that wwtp replaced oxidation pond with activated sludge and digestion\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '06005205001', 'LAGOON_AER'] = 0\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '06005205001', 'B1E'] = 1\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '06005205001', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n",
    "\n",
    "#DELHI TWP WWTP; online checks show that wwtp uses primary treatment, anaerobic digestion, and nitrification\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '26000054001', 'STBL_POND'] = 0\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '26000054001', 'F1E'] = 1\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '26000054001', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n",
    "\n",
    "#South Columbus WRP; online checks show that wwtp uses primary treatment and anaerobic digestion\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '13000051001', 'LAGOON_AER'] = 0\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '13000051001', 'B1E'] = 1\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '13000051001', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n",
    "\n",
    "#Sunnyvale, City of (WPCP); online checks show that wwtp uses ponding process and generates electricity\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '06002008001', 'B1E'] = 1\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '06002008001', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n",
    "\n",
    "#Bakersfield WWTP #2; online checks show that wwtp uses trickling filter\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '06005010001', 'D1E'] = 1\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '06005010001', 'LAGOON_AER'] = 0\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '06005010001', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n",
    "\n",
    "#MILWAUKEE MSD COMBINED - South Shore; online checks show that wwtp uses nitrification\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '55000000052', 'F1'] = 0\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '55000000052', 'F1E'] = 1\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '55000000052', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n",
    "\n",
    "#Lemay WWTP; online checks show that wwtp uses incinerator and anaerobic digestion\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '29001023002', 'B6'] = 0\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '29001023002', 'B1E'] = 1\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '29001023002', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n",
    "\n",
    "#Bissell Point WWTP; online checks show that wwtp uses incinerator, trickling filter, and digestion\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '29001023001', 'B6'] = 1\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '29001023001', 'D6'] = 1\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '29001023001', 'B1E'] = 1\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '29001023001', 'D1E'] = 1\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['CWNS_NUM'] == '29001023001', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Dz80Q3AsknY0",
   "metadata": {
    "id": "Dz80Q3AsknY0"
   },
   "outputs": [],
   "source": [
    "#rename LAGOON column to indicate that type of lagoon was not specified\n",
    "tt_werf_2022_final.rename(columns = {'LAGOON':'LAGOON_OTHER'}, inplace = True)\n",
    "\n",
    "#reset the 'TT_IDENTIFIED' column to account for manual corrections\n",
    "tt_werf_2022_final['TT_IDENTIFIED'] = tt_werf_2022_final[['LAGOON_OTHER', 'LAGOON_AER', 'LAGOON_ANAER',\n",
    "       'LAGOON_FAC', 'STBL_POND', 'C1', 'C1E', 'C2', 'C3', 'C5', 'C6', 'B1',\n",
    "       'B1E', 'B2', 'B3', 'B4', 'B5', 'B6', 'D1', 'D1E', 'D2', 'D3', 'D5', 'D6', 'E2',\n",
    "       'E2P', 'F1', 'F1E', 'I1', 'I1E', 'I2', 'I3', 'I5', 'I6', 'G1', 'G1E', 'G2',\n",
    "       'G3', 'G5', 'G6', 'H1', 'H1E', 'N1', 'N1E', 'N2', 'O1', 'O1E', 'O2', 'O3', 'O5', 'O6']].sum(axis = 1)\n",
    "\n",
    "#for facilities where the unit process nitrification was added via the 'PRES_AMMONIA_REMOVAL' column, add a note to the UP_ID_NOTE column\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['NIT_FLAG'] == 1, 'UP_ID_NOTE_2'] = \"Nitrification unit process added via 'PRES_AMMONIA_REMOVAL' column (2024)\"\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['UP_ID_NOTE'] == 'nan', 'UP_ID_NOTE'] = np.nan\n",
    "tt_werf_2022_final.loc[tt_werf_2022_final['UP_ID_NOTE_2'] == 'nan', 'UP_ID_NOTE_2'] = np.nan\n",
    "\n",
    "for index, row in tt_werf_2022_final.iterrows():\n",
    "  if pd.isna(row['UP_ID_NOTE_2']) == False:\n",
    "    if pd.isna(row['UP_ID_NOTE']) == True:\n",
    "      tt_werf_2022_final.at[index, 'UP_ID_NOTE'] = row['UP_ID_NOTE_2']\n",
    "    else:\n",
    "      tt_werf_2022_final.at[index, 'UP_ID_NOTE'] = row['UP_ID_NOTE'] + '; ' + row['UP_ID_NOTE_2']\n",
    "\n",
    "#reoder columns\n",
    "tt_werf_2022_final = tt_werf_2022_final[['CWNS_NUM', 'AED', 'AND', 'AS', 'AS-A2O', 'AS-BDENIT',\n",
    "       'AS-EA', 'AS-OD', 'AS-P', 'AS-PUREO', 'AS-SA', 'AS-SBR', 'BDENIT',\n",
    "       'BIO-P', 'BIODRY', 'BIOGAS_CWNS', 'BNIT', 'BNR', 'BS_LAGOON', 'CHEM-P',\n",
    "       'DISINF-O3', 'FBI', 'LAND_TRT', 'LIME', 'MBR-BNR', 'MHI', 'NIT','PRIMARY',\n",
    "        'TF', 'TF-BF', 'TF-RBC', 'SUM_AS', 'TF_ALL', 'BASIC_AS',\n",
    "       'AS_BNR_N', 'AS_BNR_P', 'COUNT_UP', 'BIOGAS_EL_2022', 'FLOW_2022_MGD',\n",
    "       '2022_FLOW_CAT_MGD', 'EPA_REGION','LAGOON_OTHER', 'LAGOON_AER', 'LAGOON_ANAER',\n",
    "       'LAGOON_FAC', 'STBL_POND', 'C1', 'C1E', 'C2', 'C3', 'C5', 'C6', 'B1',\n",
    "       'B1E', 'B2', 'B3', 'B4', 'B5', 'B6', 'D1', 'D1E', 'D2', 'D3', 'D5', 'D6', 'E2',\n",
    "       'E2P', 'F1', 'F1E', 'I1', 'I1E', 'I2', 'I3', 'I5', 'I6', 'G1', 'G1E', 'G2',\n",
    "       'G3', 'G5', 'G6', 'H1', 'H1E', 'N1', 'N1E', 'N2', 'O1', 'O1E', 'O2', 'O3', 'O5', 'O6',\n",
    "       'TT_IDENTIFIED', 'TT_ASSIGN_NOTE', 'UP_ID_NOTE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0Ktam0VCK6Gx",
   "metadata": {
    "id": "0Ktam0VCK6Gx"
   },
   "outputs": [],
   "source": [
    "#read in spreadsheet that contains manually corrected flow rates for top 50 wwtps by flow rate (checks done by Heroda Abera, 2024)\n",
    "flow_checks = pd.read_excel(/input_data/2022_flow_checks.xlsx')\n",
    "\n",
    "#add leading zero to CWNS ids with less than 11 digits to ensure correct merge with final dataframe\n",
    "flow_checks['CWNS_NUM'] = ['0' + str(cwns) if len(str(cwns)) < 11 else str(cwns) for cwns in flow_checks['CWNS_NUM']]\n",
    "\n",
    "#merge flow checks with final dataframe\n",
    "tt_werf_2022_final = tt_werf_2022_final.merge(flow_checks, how = 'left', on = ['CWNS_NUM'])\n",
    "\n",
    "#for wwtps that were not checked for flow rate, assume the flow reported in 2022 is correct\n",
    "tt_werf_2022_final.loc[pd.isna(tt_werf_2022_final['FLOW_2022_MGD (CHECKED)']),'FLOW_2022_MGD (CHECKED)'] = tt_werf_2022_final.loc[pd.isna(tt_werf_2022_final['FLOW_2022_MGD (CHECKED)']),'FLOW_2022_MGD']\n",
    "tt_werf_2022_final.rename(columns = {'FLOW_2022_MGD (CHECKED)':'FLOW_2022_MGD_FINAL'}, inplace = True)\n",
    "\n",
    "#drop duplicates\n",
    "tt_werf_2022_final = tt_werf_2022_final.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "S8mJQAF4kg9D",
   "metadata": {
    "id": "S8mJQAF4kg9D"
   },
   "outputs": [],
   "source": [
    "#export to csv to be used for energy and greenhouse gas emissions calculations\n",
    "tt_werf_2022_final.to_csv(/output_data/tt_assignments_2022.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
